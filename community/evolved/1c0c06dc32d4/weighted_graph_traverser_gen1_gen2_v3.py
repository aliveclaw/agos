"""Evolved strategy: Weighted Graph Traverser_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15008v1
Target module: knowledge.graph
Generated: 2026-02-18T08:21:13.475664
Defines: KnowledgeGraph
Code hash: 589c33894b1b69e3

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'from collections import defaultdict, deque\nimport math\nimport json\n\nclass KnowledgeGraph:\n    def __init__(self):\n        self.edges = defaultdict(list)\n        self.reverse_edges = defaultdict(list)\n        self.node_types = {}\n        self.node_attributes = defaultdict(dict)\n        self.relation_weights = defaultdict(lambda: 1.0)\n        self.relation_types = defaultdict(set)\n        self.temporal_edges = defaultdict(list)\n        self.inference_cache = {}\n    \n    def add(self, src, rel, dst, weight=1.0, src_type=None, dst_type=None, timestamp=None, attributes=None):\n        edge_data = {\'weight\': weight, \'timestamp\': timestamp}\n        self.edges[src].append((dst, rel, edge_data))\n        self.reverse_edges[dst].append((src, rel, edge_data))\n        \n        if src_type:\n            self.node_types[src] = src_type\n        if dst_type:\n            self.node_types[dst] = dst_type\n        if attributes:\n            self.node_attributes[src].update(attributes.get(\'src\', {}))\n            self.node_attributes[dst].update(attributes.get(\'dst\', {}))\n            \n        self.relation_weights[rel] = max(self.relation_weights[rel], weight)\n        self.relation_types[rel].add((src_type, dst_type))\n        \n        if timestamp:\n            self.temporal_edges[timestamp].append((src, rel, dst, weight))\n        \n        # Clear inference cache when graph changes\n        self.inference_cache.clear()\n    \n    def traverse(self, start, max_depth=3, decay=0.7, min_score=0.01, context=None):\n        cache_key = (start, max_depth, decay, min_score, str(context))\n        if cache_key in self.inference_cache:\n            return self.inference_cache[cache_key]\n            \n        visited = {}\n        queue = deque([(start, 1.0, 0, [], set())])\n        \n        while queue:\n            node, score, depth, path, visited_nodes = queue.popleft()\n            \n            if node in visited or depth > max_depth or score < min_score:\n                continue\n                \n            visited[node] = {\n                \'score\': round(score, 4),\n                \'depth\': depth,\n                \'path\': path.copy(),\n                \'type\': self.node_types.get(node),\n                \'attributes\': self.node_attributes.get(node, {})\n            }\n            \n            new_visited = visited_nodes | {node}\n            \n            for dst, rel, edge_data in self.edges.get(node, []):\n                if dst not in visited_nodes:  # Prevent cycles\n                    new_path = path + [rel]\n                    relevance_boost = 1.0 + (0.2 * self._calculate_relevance(rel, new_path, context))\n                    type_boost = self._calculate_type_compatibility(node, dst, rel)\n                    temporal_boost = self._calculate_temporal_relevance(edge_data.get(\'timestamp\'))\n                    \n                    new_score = score * edge_data[\'weight\'] * decay * relevance_boost * type_boost * temporal_boost\n                    queue.append((dst, new_score, depth + 1, new_path, new_visited))\n        \n        self.inference_cache[cache_key] = visited\n        return visited\n    \n    def _calculate_relevance(self, relation, path, context=None):\n        """Enhanced relevance calculation with context awareness"""\n        base_relevance = math.log(self.relation_weights[relation] + 1)\n        path_coherence = len(set(path)) / max(len(path), 1)\n        \n        # Context boost\n        context_boost = 1.0\n        if context and relation in context.get(\'preferred_relations\', []):\n            context_boost = 1.5\n        \n        # Relation frequency boost\n        freq_boost = min(2.0, 1.0 + len(self.relation_types[relation]) * 0.1)\n        \n        return base_relevance * path_coherence * context_boost * freq_boost\n    \n    def _calculate_type_compatibility(self, src, dst, relation):\n        """Calculate compatibility score based on node types"""\n        src_type = self.node_types.get(src)\n        dst_type = self.node_types.get(dst)\n        \n        if not src_type or not dst_type:\n            return 1.0\n            \n        # Boost score for known type patterns\n        type_pattern = (src_type, dst_type)\n        if type_pattern in self.relation_types[relation]:\n            return 1.2\n        return 1.0\n    \n    def _calculate_temporal_relevance(self, timestamp):\n        """Calculate temporal relevance boost for recent connections"""\n        if not timestamp:\n            return 1.0\n        # Simple recency boost - more sophisticated temporal logic could be added\n        return min(1.3, 1.0 + 0.1 * math.log(timestamp + 1))\n    \n    def find_paths(self, start, end, max_depth=4, max_paths=10):\n        """Find multiple paths between nodes with ranking"""\n        paths = []\n        queue = deque([(start, [start], 1.0, 0)])\n        \n        while queue and len(paths) < max_paths:\n            node, path, score, depth = queue.popleft()\n            \n            if depth > max_depth:\n                continue\n                \n            if node == end:\n                paths.append({\n                    \'path\': path,\n                    \'score\': round(score, 4),\n                    \'length\': len(path) - 1\n                })\n                continue\n            \n            for dst, rel, edge_data in self.edges.get(node, []):\n                if dst not in path:\n                    new_path = path + [dst]\n                    new_score = score * edge_data[\'weight\'] * 0.8\n                    queue.append((dst, new_path, new_score, depth + 1))\n        \n        return sorted(paths, key=lambda x: x[\'score\'], reverse=True)\n    \n    def infer_relations(self, node, depth=2):\n        """Infer potential new relations based on graph patterns"""\n        traversal = self.traverse(node, max_depth=depth)\n        inferences = []\n        \n        for target_node, data in traversal.items():\n            if target_node != node and data[\'depth\'] > 1:\n                confidence = data[\'score\'] * (1.0 / data[\'depth\'])\n                if confidence > 0.1:\n                    inferences.append({\n                        \'target\': target_node,\n                        \'confidence\': round(confidence, 3),\n                        \'reasoning_path\': data[\'path\']\n                    })\n        \n        return sorted(inferences, key=lambda x: x[\'confidence\'], reverse=True)\n    \n    def export_subgraph(self, nodes, include_metadata=True):\n        """Export a subgraph as JSON"""\n        subgraph = {\n            \'nodes\': {},\n            \'edges\': []\n        }\n        \n        for node in nodes:\n            subgraph[\'nodes\'][node] = {\n                \'type\': self.node_types.get(node),\n                \'attributes\': self.node_attributes.get(node, {}) if include_metadata else {}\n            }\n            \n            for dst, rel, edge_data in self.edges.get(node, []):\n                if dst in nodes:\n                    edge = {\n                        \'src\': node,\n                        \'rel\': rel,\n                        \'dst\': dst,\n                        \'weight\': edge_data[\'weight\']\n                    }\n                    if include_metadata and edge_data.get(\'timestamp\'):\n                        edge[\'timestamp\'] = edge_data[\'timestamp\']\n                    subgraph[\'edges\'].append(edge)\n        \n        return json.dumps(subgraph, indent=2)'

PATTERN_HASH = "589c33894b1b69e3"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:weighted_graph_traverser_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class WeightedGraphTraverserGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Weighted Graph Traverser_gen1_gen2"""

    name = "weighted_graph_traverser_gen1_gen2"
    target_module = "knowledge.graph"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for weighted_graph_traverser_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.graph"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15008v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
