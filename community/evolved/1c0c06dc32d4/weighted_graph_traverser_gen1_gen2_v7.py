"""Evolved strategy: Weighted Graph Traverser_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15011v1
Target module: knowledge.graph
Generated: 2026-02-18T09:17:57.990725
Defines: KnowledgeGraph
Code hash: bed768c72eb3e14b

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = "from collections import defaultdict, deque\nimport json\nimport math\nimport heapq\n\nclass KnowledgeGraph:\n    def __init__(self):\n        self.edges = defaultdict(list)\n        self.reverse_edges = defaultdict(list)\n        self.node_metadata = defaultdict(dict)\n        self.relation_types = set()\n        self.node_embeddings = defaultdict(list)\n        self.relation_weights = defaultdict(float)\n    \n    def add(self, src, rel, dst, weight=1.0, metadata=None):\n        self.edges[src].append((dst, rel, weight))\n        self.reverse_edges[dst].append((src, rel, weight))\n        self.relation_types.add(rel)\n        self.relation_weights[rel] = max(self.relation_weights[rel], weight)\n        if metadata:\n            self.node_metadata[src].update(metadata)\n    \n    def add_embedding(self, node, embedding):\n        self.node_embeddings[node] = embedding\n    \n    def semantic_similarity(self, node1, node2):\n        if not self.node_embeddings[node1] or not self.node_embeddings[node2]:\n            return 0.0\n        \n        emb1, emb2 = self.node_embeddings[node1], self.node_embeddings[node2]\n        dot_product = sum(a * b for a, b in zip(emb1, emb2))\n        norm1 = math.sqrt(sum(a * a for a in emb1))\n        norm2 = math.sqrt(sum(b * b for b in emb2))\n        \n        return dot_product / (norm1 * norm2) if norm1 * norm2 > 0 else 0.0\n    \n    def traverse(self, start, max_depth=3, decay=0.7, relation_filter=None, semantic_boost=True):\n        visited = {}\n        # Use priority queue for better traversal ordering\n        heap = [(-1.0, 0, start, [])]\n        \n        while heap:\n            neg_score, depth, node, path = heapq.heappop(heap)\n            score = -neg_score\n            \n            if node in visited or depth > max_depth:\n                continue\n            \n            # Apply semantic similarity boost\n            if semantic_boost and depth > 0:\n                similarity = self.semantic_similarity(start, node)\n                score *= (1.0 + similarity * 0.5)\n                \n            visited[node] = {\n                'score': round(score, 4),\n                'depth': depth,\n                'path': path.copy(),\n                'metadata': self.node_metadata.get(node, {})\n            }\n            \n            for dst, rel, w in self.edges.get(node, []):\n                if relation_filter and rel not in relation_filter:\n                    continue\n                new_path = path + [rel]\n                new_score = score * w * decay * self.relation_weights.get(rel, 1.0)\n                heapq.heappush(heap, (-new_score, depth + 1, dst, new_path))\n        \n        return dict(sorted(visited.items(), key=lambda x: x[1]['score'], reverse=True))\n    \n    def find_paths(self, start, end, max_depth=3, max_paths=10):\n        paths = []\n        queue = deque([(start, [start], 1.0, 0, [])])\n        \n        while queue and len(paths) < max_paths:\n            node, path, score, depth, relations = queue.popleft()\n            \n            if depth > max_depth:\n                continue\n                \n            if node == end:\n                semantic_bonus = self.semantic_similarity(start, end) * 0.3\n                final_score = score + semantic_bonus\n                paths.append({\n                    'path': path,\n                    'score': round(final_score, 4),\n                    'relations': relations,\n                    'length': len(path) - 1\n                })\n                continue\n            \n            for dst, rel, w in self.edges.get(node, []):\n                if dst not in path:  # Avoid cycles\n                    new_path = path + [dst]\n                    new_relations = relations + [rel]\n                    new_score = score * w * self.relation_weights.get(rel, 1.0)\n                    queue.append((dst, new_path, new_score, depth + 1, new_relations))\n        \n        return sorted(paths, key=lambda x: x['score'], reverse=True)\n    \n    def get_neighbors(self, node, relation_type=None, direction='out'):\n        if direction == 'out':\n            edges = self.edges.get(node, [])\n        elif direction == 'in':\n            edges = self.reverse_edges.get(node, [])\n        else:  # both\n            edges = self.edges.get(node, []) + self.reverse_edges.get(node, [])\n        \n        neighbors = []\n        for dst, rel, w in edges:\n            if not relation_type or rel == relation_type:\n                neighbors.append({\n                    'node': dst,\n                    'relation': rel,\n                    'weight': w,\n                    'metadata': self.node_metadata.get(dst, {})\n                })\n        \n        return sorted(neighbors, key=lambda x: x['weight'], reverse=True)\n    \n    def cluster_nodes(self, similarity_threshold=0.7):\n        clusters = []\n        nodes = list(self.node_embeddings.keys())\n        visited = set()\n        \n        for node in nodes:\n            if node in visited:\n                continue\n                \n            cluster = [node]\n            visited.add(node)\n            \n            for other in nodes:\n                if other not in visited:\n                    similarity = self.semantic_similarity(node, other)\n                    if similarity >= similarity_threshold:\n                        cluster.append(other)\n                        visited.add(other)\n            \n            if len(cluster) > 1:\n                clusters.append(cluster)\n        \n        return clusters\n    \n    def export_subgraph(self, nodes):\n        subgraph = {\n            'nodes': {},\n            'edges': []\n        }\n        \n        node_set = set(nodes)\n        for node in nodes:\n            subgraph['nodes'][node] = {\n                'metadata': self.node_metadata.get(node, {}),\n                'embedding': self.node_embeddings.get(node, [])\n            }\n            \n            for dst, rel, w in self.edges.get(node, []):\n                if dst in node_set:\n                    subgraph['edges'].append({\n                        'src': node,\n                        'dst': dst,\n                        'relation': rel,\n                        'weight': w\n                    })\n        \n        return subgraph"

PATTERN_HASH = "bed768c72eb3e14b"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:weighted_graph_traverser_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class WeightedGraphTraverserGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Weighted Graph Traverser_gen1_gen2"""

    name = "weighted_graph_traverser_gen1_gen2"
    target_module = "knowledge.graph"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for weighted_graph_traverser_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.graph"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15011v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
