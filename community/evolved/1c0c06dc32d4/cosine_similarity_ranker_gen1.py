"""Evolved strategy: Cosine Similarity Ranker_gen1

Auto-generated by agos evolution engine.
Source paper: 2602.15029v1
Target module: knowledge.semantic
Generated: 2026-02-18T07:49:27.999580
Defines: SemanticIndex
Code hash: 7298ac1a643b27b6

Sandbox output: Indexed 6 documents with vocabulary size: 19
Top results: [(0, 0.798), (3, 0.389), (1, 0.0)]
PASS: Enhanced semantic search system validated

"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import math\nimport re\nfrom collections import Counter, defaultdict\n\nclass SemanticIndex:\n    def __init__(self):\n        self.docs = []\n        self.vocab = set()\n        self.idf_cache = {}\n        self.doc_vectors = []\n        \n    def add_document(self, text, doc_id=None):\n        doc_id = doc_id or len(self.docs)\n        self.docs.append((doc_id, text))\n        words = self._tokenize(text)\n        self.vocab.update(words)\n        self._invalidate_cache()\n        return doc_id\n    \n    def _tokenize(self, text):\n        return re.findall(r\'\\b\\w+\\b\', text.lower())\n    \n    def _compute_idf(self):\n        if self.idf_cache:\n            return\n        doc_count = len(self.docs)\n        word_doc_freq = defaultdict(int)\n        \n        for _, doc in self.docs:\n            words = set(self._tokenize(doc))\n            for word in words:\n                word_doc_freq[word] += 1\n        \n        for word in self.vocab:\n            self.idf_cache[word] = math.log(doc_count / max(word_doc_freq[word], 1))\n    \n    def _tfidf_vector(self, text):\n        words = self._tokenize(text)\n        tf = Counter(words)\n        doc_len = len(words)\n        \n        vector = []\n        for word in sorted(self.vocab):\n            tf_score = tf.get(word, 0) / max(doc_len, 1)\n            idf_score = self.idf_cache.get(word, 0)\n            vector.append(tf_score * idf_score)\n        return vector\n    \n    def _cosine_similarity(self, vec1, vec2):\n        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n        norm1 = math.sqrt(sum(x * x for x in vec1))\n        norm2 = math.sqrt(sum(x * x for x in vec2))\n        return dot_product / (norm1 * norm2) if norm1 and norm2 else 0.0\n    \n    def build_index(self):\n        self._compute_idf()\n        self.doc_vectors = []\n        for doc_id, doc in self.docs:\n            vector = self._tfidf_vector(doc)\n            self.doc_vectors.append((doc_id, vector))\n    \n    def search(self, query, top_k=None):\n        if not self.doc_vectors:\n            self.build_index()\n        \n        query_vector = self._tfidf_vector(query)\n        scores = []\n        \n        for (doc_id, doc_vector), (_, original_doc) in zip(self.doc_vectors, self.docs):\n            similarity = self._cosine_similarity(query_vector, doc_vector)\n            scores.append((doc_id, similarity, original_doc))\n        \n        scores.sort(key=lambda x: -x[1])\n        return scores[:top_k] if top_k else scores\n    \n    def _invalidate_cache(self):\n        self.idf_cache.clear()\n        self.doc_vectors.clear()\n\n# Test the semantic search system\nindex = SemanticIndex()\ndocs = [\n    \'agent memory retrieval system\',\n    \'semantic search with vectors\',\n    \'policy engine rule processing\',\n    \'agent memory search optimization\',\n    \'knowledge base semantic indexing\',\n    \'vector similarity computation\'\n]\n\nfor doc in docs:\n    index.add_document(doc)\n\nindex.build_index()\n\n# Test queries\ntest_queries = [\'agent memory\', \'semantic vectors\', \'policy rules\']\nfor query in test_queries:\n    results = index.search(query, top_k=3)\n    top_score = results[0][1]\n    bottom_score = results[-1][1]\n    assert top_score >= bottom_score, f"Ranking failed for query: {query}"\n\nprint(f\'Indexed {len(docs)} documents with vocabulary size: {len(index.vocab)}\')\nresults = index.search(\'agent memory retrieval\', top_k=3)\nprint(f\'Top results: {[(doc_id, round(score, 3)) for doc_id, score, _ in results]}\')\nprint(\'PASS: Enhanced semantic search system validated\')'

PATTERN_HASH = "7298ac1a643b27b6"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:cosine_similarity_ranker_gen1>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class CosineSimilarityRankerGen1Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Cosine Similarity Ranker_gen1"""

    name = "cosine_similarity_ranker_gen1"
    target_module = "knowledge.semantic"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for cosine_similarity_ranker_gen1: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.semantic"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15029v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
