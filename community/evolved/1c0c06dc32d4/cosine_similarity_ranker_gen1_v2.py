"""Evolved strategy: Cosine Similarity Ranker_gen1

Auto-generated by agos evolution engine.
Source paper: 2602.15021v1
Target module: knowledge.semantic
Generated: 2026-02-18T07:53:35.727974
Defines: SemanticRanker
Code hash: 50ef0ed687556d20

Sandbox output: Query: "agent memory"
Rankings: [(3, 0.5944), (0, 0.5227), (1, 0.0), (2, 0.0), (4, 0.0), (5, 0.0)]
PASS: Enhanced semantic ranker with TF-IDF validated

"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import math\nimport re\nfrom collections import Counter, defaultdict\n\nclass SemanticRanker:\n    def __init__(self, docs=None):\n        self.docs = docs or []\n        self.vocab = set()\n        self.idf_cache = {}\n        self._build_vocab()\n    \n    def _build_vocab(self):\n        for doc in self.docs:\n            self.vocab.update(self._tokenize(doc))\n        self.vocab = sorted(self.vocab)\n        self._compute_idf()\n    \n    def _tokenize(self, text):\n        return re.findall(r\'\\b[a-z]+\\b\', text.lower())\n    \n    def _compute_idf(self):\n        doc_freq = defaultdict(int)\n        for doc in self.docs:\n            words = set(self._tokenize(doc))\n            for word in words:\n                doc_freq[word] += 1\n        \n        n_docs = len(self.docs)\n        for word in self.vocab:\n            self.idf_cache[word] = math.log(n_docs / max(doc_freq[word], 1))\n    \n    def _tfidf_vector(self, text):\n        words = self._tokenize(text)\n        tf = Counter(words)\n        doc_len = max(len(words), 1)\n        \n        vector = []\n        for word in self.vocab:\n            tf_score = tf.get(word, 0) / doc_len\n            idf_score = self.idf_cache.get(word, 0)\n            vector.append(tf_score * idf_score)\n        return vector\n    \n    def _cosine_similarity(self, vec_a, vec_b):\n        dot_product = sum(a * b for a, b in zip(vec_a, vec_b))\n        norm_a = math.sqrt(sum(a * a for a in vec_a))\n        norm_b = math.sqrt(sum(b * b for b in vec_b))\n        return dot_product / (norm_a * norm_b) if norm_a and norm_b else 0.0\n    \n    def rank_documents(self, query):\n        query_vec = self._tfidf_vector(query)\n        scores = []\n        \n        for i, doc in enumerate(self.docs):\n            doc_vec = self._tfidf_vector(doc)\n            similarity = self._cosine_similarity(query_vec, doc_vec)\n            scores.append((i, round(similarity, 4)))\n        \n        return sorted(scores, key=lambda x: -x[1])\n\n# Test the semantic ranker\ndocs = [\'agent memory retrieval system\', \'semantic search vectors database\',\n        \'policy engine rules framework\', \'agent memory search optimization\',\n        \'neural network embeddings\', \'knowledge graph traversal\']\n\nranker = SemanticRanker(docs)\nquery = \'agent memory\'\nrankings = ranker.rank_documents(query)\n\nassert rankings[0][1] > rankings[-1][1]\nassert len(rankings) == len(docs)\n\nprint(f\'Query: "{query}"\')\nprint(f\'Rankings: {rankings}\')\nprint(\'PASS: Enhanced semantic ranker with TF-IDF validated\')'

PATTERN_HASH = "50ef0ed687556d20"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:cosine_similarity_ranker_gen1>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class CosineSimilarityRankerGen1Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Cosine Similarity Ranker_gen1"""

    name = "cosine_similarity_ranker_gen1"
    target_module = "knowledge.semantic"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for cosine_similarity_ranker_gen1: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.semantic"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15021v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
