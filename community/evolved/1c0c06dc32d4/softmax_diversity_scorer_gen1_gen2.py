"""Evolved strategy: Softmax Diversity Scorer_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15017v1
Target module: knowledge.semantic
Generated: 2026-02-18T08:42:28.975477
Defines: SemanticScorer
Code hash: 6b29239709acf62c

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = "import math\nimport random\nimport re\nfrom collections import defaultdict, Counter\n\nclass SemanticScorer:\n    def __init__(self, temperature=0.3, diversity_weight=0.2, context_weight=0.15):\n        self.temperature = max(temperature, 0.01)\n        self.diversity_weight = diversity_weight\n        self.context_weight = context_weight\n        self.history = defaultdict(float)\n        self.context_memory = defaultdict(list)\n        self.word_embeddings = {}\n        self._build_simple_embeddings()\n    \n    def _build_simple_embeddings(self):\n        # Simple word co-occurrence based embeddings\n        common_patterns = {\n            'positive': ['good', 'great', 'excellent', 'amazing', 'wonderful', 'best'],\n            'negative': ['bad', 'terrible', 'awful', 'worst', 'horrible', 'poor'],\n            'technical': ['system', 'code', 'function', 'method', 'class', 'algorithm'],\n            'action': ['run', 'execute', 'process', 'handle', 'manage', 'control'],\n            'data': ['information', 'content', 'text', 'value', 'result', 'output']\n        }\n        \n        for category, words in common_patterns.items():\n            for word in words:\n                self.word_embeddings[word] = category\n    \n    def softmax_score(self, values, labels=None, context=None):\n        if not values: return []\n        \n        # Normalize input values\n        mean_val = sum(values) / len(values)\n        std_val = math.sqrt(sum((v - mean_val) ** 2 for v in values) / len(values))\n        if std_val > 0:\n            values = [(v - mean_val) / std_val for v in values]\n        \n        # Apply context boost if available\n        if context and labels and self.context_weight > 0:\n            context_scores = [self._context_relevance(label, context) for label in labels]\n            values = [v + self.context_weight * cs for v, cs in zip(values, context_scores)]\n        \n        # Apply temperature scaling\n        exp_vals = [math.exp(v / self.temperature) for v in values]\n        total = sum(exp_vals)\n        base_scores = [v / total for v in exp_vals]\n        \n        # Apply diversity penalty if labels provided\n        if labels and self.diversity_weight > 0:\n            diversity_penalties = [self.history.get(label, 0) for label in labels]\n            max_penalty = max(diversity_penalties) if diversity_penalties else 0\n            \n            if max_penalty > 0:\n                adjusted_vals = []\n                for i, val in enumerate(values):\n                    penalty = diversity_penalties[i] / (max_penalty + 1e-6)\n                    adjusted_val = val - (self.diversity_weight * penalty)\n                    adjusted_vals.append(adjusted_val)\n                \n                # Recalculate softmax with diversity adjustment\n                exp_vals = [math.exp(v / self.temperature) for v in adjusted_vals]\n                total = sum(exp_vals)\n                base_scores = [v / total for v in exp_vals]\n        \n        return base_scores\n    \n    def _context_relevance(self, label, context):\n        if not context or not label:\n            return 0.0\n        \n        context_words = set(re.findall(r'\\b\\w+\\b', context.lower()))\n        label_words = set(re.findall(r'\\b\\w+\\b', label.lower()))\n        \n        # Direct word overlap\n        overlap = len(context_words & label_words)\n        total_words = len(context_words | label_words)\n        \n        if total_words == 0:\n            return 0.0\n        \n        # Semantic category overlap\n        context_categories = set(self.word_embeddings.get(word, 'unknown') \n                               for word in context_words if word in self.word_embeddings)\n        label_categories = set(self.word_embeddings.get(word, 'unknown') \n                             for word in label_words if word in self.word_embeddings)\n        \n        category_overlap = len(context_categories & label_categories)\n        \n        return (overlap / total_words) + (0.3 * category_overlap / max(len(context_categories | label_categories), 1))\n    \n    def update_history(self, selected_label, decay=0.9, context=None):\n        # Decay all history values\n        for label in self.history:\n            self.history[label] *= decay\n        \n        # Increment selected item\n        self.history[selected_label] += 1.0\n        \n        # Update context memory\n        if context:\n            self.context_memory[selected_label].append(context)\n            # Keep only recent contexts\n            if len(self.context_memory[selected_label]) > 5:\n                self.context_memory[selected_label].pop(0)\n    \n    def semantic_similarity(self, text1, text2):\n        if not text1 or not text2:\n            return 0.0\n        \n        # Normalize and tokenize\n        words1 = Counter(re.findall(r'\\b\\w+\\b', text1.lower()))\n        words2 = Counter(re.findall(r'\\b\\w+\\b', text2.lower()))\n        \n        if not words1 or not words2:\n            return 0.0\n        \n        # Jaccard similarity with frequency weighting\n        intersection = sum((words1 & words2).values())\n        union = sum((words1 | words2).values())\n        jaccard = intersection / union if union > 0 else 0.0\n        \n        # Cosine similarity\n        dot_product = sum(words1[word] * words2[word] for word in words1 if word in words2)\n        norm1 = math.sqrt(sum(count ** 2 for count in words1.values()))\n        norm2 = math.sqrt(sum(count ** 2 for count in words2.values()))\n        cosine = dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0.0\n        \n        # Semantic category similarity\n        cats1 = set(self.word_embeddings.get(word, 'unknown') for word in words1)\n        cats2 = set(self.word_embeddings.get(word, 'unknown') for word in words2)\n        semantic_sim = len(cats1 & cats2) / len(cats1 | cats2) if cats1 | cats2 else 0.0\n        \n        # Combined similarity score\n        return 0.4 * jaccard + 0.4 * cosine + 0.2 * semantic_sim\n    \n    def get_contextual_recommendations(self, query, candidates, top_k=3):\n        if not candidates:\n            return []\n        \n        similarities = [self.semantic_similarity(query, candidate) for candidate in candidates]\n        scores = self.softmax_score(similarities, candidates, query)\n        \n        # Combine with historical context\n        enhanced_scores = []\n        for i, (candidate, score) in enumerate(zip(candidates, scores)):\n            context_boost = 0.0\n            if candidate in self.context_memory:\n                for past_context in self.context_memory[candidate]:\n                    context_boost += self.semantic_similarity(query, past_context)\n                context_boost /= len(self.context_memory[candidate])\n            \n            enhanced_score = score + 0.1 * context_boost\n            enhanced_scores.append((candidate, enhanced_score))\n        \n        # Sort and return top-k\n        enhanced_scores.sort(key=lambda x: x[1], reverse=True)\n        return enhanced_scores[:top_k]"

PATTERN_HASH = "6b29239709acf62c"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:softmax_diversity_scorer_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class SoftmaxDiversityScorerGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Softmax Diversity Scorer_gen1_gen2"""

    name = "softmax_diversity_scorer_gen1_gen2"
    target_module = "knowledge.semantic"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for softmax_diversity_scorer_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.semantic"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15017v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
