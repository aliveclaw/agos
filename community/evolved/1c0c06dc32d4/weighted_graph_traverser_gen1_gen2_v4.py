"""Evolved strategy: Weighted Graph Traverser_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15025v1
Target module: knowledge.graph
Generated: 2026-02-18T08:41:25.121915
Defines: KnowledgeGraph
Code hash: 4f1eab57d94c4cbd

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'from collections import defaultdict, deque\nimport math\nimport json\nimport re\n\nclass KnowledgeGraph:\n    def __init__(self):\n        self.edges = defaultdict(list)\n        self.reverse_edges = defaultdict(list)\n        self.node_types = {}\n        self.relation_weights = defaultdict(lambda: 1.0)\n        self.node_attributes = defaultdict(dict)\n        self.relation_types = set()\n        self.centrality_cache = {}\n        \n    def add(self, src, rel, dst, weight=1.0, src_type=None, dst_type=None, **attributes):\n        self.edges[src].append((dst, rel, weight))\n        self.reverse_edges[dst].append((src, rel, weight))\n        if src_type:\n            self.node_types[src] = src_type\n        if dst_type:\n            self.node_types[dst] = dst_type\n        self.relation_weights[rel] = weight\n        self.relation_types.add(rel)\n        \n        # Store additional attributes\n        if attributes:\n            self.node_attributes[src].update(attributes.get(\'src_attrs\', {}))\n            self.node_attributes[dst].update(attributes.get(\'dst_attrs\', {}))\n        \n        # Invalidate centrality cache\n        self.centrality_cache.clear()\n    \n    def traverse(self, start, max_depth=3, decay=0.7, min_score=0.01, filter_types=None):\n        visited = {}\n        queue = deque([(start, 1.0, 0, [])])\n        paths = defaultdict(list)\n        \n        while queue:\n            node, score, depth, path = queue.popleft()\n            \n            # Type filtering\n            if filter_types and self.node_types.get(node) not in filter_types:\n                continue\n                \n            if node in visited and visited[node] >= score:\n                continue\n            if depth > max_depth or score < min_score:\n                continue\n                \n            visited[node] = round(max(visited.get(node, 0), score), 4)\n            current_path = path + [node]\n            paths[node].append((current_path, score))\n            \n            for dst, rel, w in self.edges.get(node, []):\n                # Adaptive decay with centrality boost\n                centrality_boost = self._get_centrality(dst)\n                rel_decay = decay * self.relation_weights.get(rel, 1.0) * (1 + centrality_boost * 0.1)\n                new_score = score * w * rel_decay\n                queue.append((dst, new_score, depth + 1, current_path))\n        \n        return visited, dict(paths)\n    \n    def find_connections(self, node1, node2, max_depth=4, strategy=\'shortest\'):\n        """Find paths between nodes with multiple strategies"""\n        paths = []\n        queue = deque([(node1, [node1], 1.0, 0)])\n        visited = set() if strategy == \'shortest\' else None\n        \n        while queue:\n            current, path, score, depth = queue.popleft()\n            \n            if strategy == \'shortest\' and current in visited:\n                continue\n            if visited is not None:\n                visited.add(current)\n                \n            if current == node2:\n                paths.append((path, round(score, 4)))\n                if strategy == \'shortest\':\n                    break\n                continue\n                    \n            if depth >= max_depth:\n                continue\n                \n            for dst, rel, w in self.edges.get(current, []):\n                if dst not in path:  # Avoid cycles\n                    new_score = score * w * self.relation_weights.get(rel, 1.0)\n                    queue.append((dst, path + [dst], new_score, depth + 1))\n        \n        # Sort by strategy\n        if strategy == \'strongest\':\n            paths.sort(key=lambda x: x[1], reverse=True)\n        elif strategy == \'shortest\':\n            paths.sort(key=lambda x: len(x[0]))\n            \n        return paths\n    \n    def _get_centrality(self, node):\n        """Calculate and cache node centrality"""\n        if node in self.centrality_cache:\n            return self.centrality_cache[node]\n            \n        # Simple degree centrality\n        in_degree = len(self.reverse_edges.get(node, []))\n        out_degree = len(self.edges.get(node, []))\n        centrality = math.log(1 + in_degree + out_degree) / 10\n        \n        self.centrality_cache[node] = centrality\n        return centrality\n    \n    def cluster_nodes(self, similarity_threshold=0.3):\n        """Group nodes by structural similarity"""\n        clusters = []\n        processed = set()\n        \n        for node in self.edges.keys():\n            if node in processed:\n                continue\n                \n            cluster = [node]\n            node_relations = set(rel for _, rel, _ in self.edges[node])\n            \n            for other in self.edges.keys():\n                if other == node or other in processed:\n                    continue\n                    \n                other_relations = set(rel for _, rel, _ in self.edges[other])\n                if node_relations and other_relations:\n                    similarity = len(node_relations & other_relations) / len(node_relations | other_relations)\n                    if similarity >= similarity_threshold:\n                        cluster.append(other)\n                        processed.add(other)\n            \n            processed.add(node)\n            if len(cluster) > 1:\n                clusters.append(cluster)\n                \n        return clusters\n    \n    def query(self, pattern, max_results=10):\n        """Pattern-based querying with regex support"""\n        results = []\n        \n        for node in list(self.edges.keys()) + list(self.reverse_edges.keys()):\n            if re.search(pattern, str(node), re.IGNORECASE):\n                centrality = self._get_centrality(node)\n                results.append((node, centrality))\n        \n        results.sort(key=lambda x: x[1], reverse=True)\n        return [node for node, _ in results[:max_results]]\n    \n    def export_subgraph(self, nodes, include_neighbors=True):\n        """Export a subgraph as JSON"""\n        if include_neighbors:\n            expanded_nodes = set(nodes)\n            for node in nodes:\n                expanded_nodes.update(dst for dst, _, _ in self.edges.get(node, []))\n                expanded_nodes.update(src for src, _, _ in self.reverse_edges.get(node, []))\n            nodes = expanded_nodes\n        \n        subgraph = {\n            \'nodes\': {node: {\n                \'type\': self.node_types.get(node),\n                \'attributes\': self.node_attributes.get(node, {})\n            } for node in nodes},\n            \'edges\': []\n        }\n        \n        for src in nodes:\n            for dst, rel, weight in self.edges.get(src, []):\n                if dst in nodes:\n                    subgraph[\'edges\'].append({\n                        \'src\': src, \'dst\': dst, \'rel\': rel, \'weight\': weight\n                    })\n        \n        return subgraph\n    \n    def get_stats(self):\n        """Return graph statistics"""\n        all_nodes = set(self.edges.keys()) | set(self.reverse_edges.keys())\n        total_edges = sum(len(edges) for edges in self.edges.values())\n        \n        return {\n            \'nodes\': len(all_nodes),\n            \'edges\': total_edges,\n            \'relation_types\': len(self.relation_types),\n            \'node_types\': len(set(self.node_types.values())),\n            \'avg_degree\': round(total_edges / len(all_nodes), 2) if all_nodes else 0\n        }'

PATTERN_HASH = "4f1eab57d94c4cbd"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:weighted_graph_traverser_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class WeightedGraphTraverserGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Weighted Graph Traverser_gen1_gen2"""

    name = "weighted_graph_traverser_gen1_gen2"
    target_module = "knowledge.graph"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for weighted_graph_traverser_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.graph"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15025v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
