"""Evolved strategy: Strategy Selector_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.14993v1
Target module: orchestration.planner
Generated: 2026-02-18T08:44:51.866674
Defines: StrategyRecord, select_strategy, create_adaptive_planner
Code hash: 78e75c5499589bc7

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import math\nimport random\nfrom collections import defaultdict, deque\n\nclass StrategyRecord:\n    def __init__(self, name):\n        self.name = name\n        self.successes = 0\n        self.failures = 0\n        self.total_tokens = 0\n        self.recent_outcomes = deque(maxlen=15)  # More efficient bounded queue\n        self.context_performance = defaultdict(lambda: {\'success\': 0, \'total\': 0, \'tokens\': 0})\n        self.execution_times = deque(maxlen=10)\n        self.complexity_scores = deque(maxlen=10)\n        \n    @property\n    def score(self):\n        total = self.successes + self.failures\n        if total == 0: \n            return 0.5\n        \n        # Enhanced success rate with adaptive confidence\n        success_rate = self.successes / total\n        confidence = min(1.0, math.sqrt(total / 8))  # Sqrt for smoother confidence growth\n        \n        # Multi-factor efficiency scoring\n        avg_tokens = self.total_tokens / total\n        token_efficiency = 1.0 / (1 + math.log(1 + avg_tokens / 800))  # More generous threshold\n        \n        # Recent performance with momentum detection\n        recent_boost = 0\n        if len(self.recent_outcomes) >= 4:\n            recent_window = list(self.recent_outcomes)[-6:]\n            recent_success = sum(recent_window) / len(recent_window)\n            momentum = self._calculate_momentum(recent_window)\n            recent_boost = 0.15 * (recent_success - success_rate) + 0.05 * momentum\n        \n        # Context adaptability bonus\n        context_bonus = self._calculate_context_adaptability()\n        \n        # Performance stability factor\n        stability = self._calculate_stability()\n        \n        # Composite scoring with dynamic weights\n        base_score = (0.5 * success_rate + \n                     0.25 * token_efficiency + \n                     0.15 * stability + \n                     0.1 * context_bonus)\n        \n        final_score = (confidence * (base_score + recent_boost) + \n                      (1 - confidence) * 0.5)\n        \n        return round(min(1.0, max(0.0, final_score)), 3)\n    \n    def _calculate_momentum(self, outcomes):\n        if len(outcomes) < 3:\n            return 0\n        # Calculate trend in recent outcomes\n        weights = [i + 1 for i in range(len(outcomes))]\n        weighted_avg = sum(o * w for o, w in zip(outcomes, weights)) / sum(weights)\n        simple_avg = sum(outcomes) / len(outcomes)\n        return weighted_avg - simple_avg\n    \n    def _calculate_context_adaptability(self):\n        if not self.context_performance:\n            return 0\n        \n        context_scores = []\n        for ctx_data in self.context_performance.values():\n            if ctx_data[\'total\'] > 0:\n                ctx_success = ctx_data[\'success\'] / ctx_data[\'total\']\n                context_scores.append(ctx_success)\n        \n        if not context_scores:\n            return 0\n        \n        # Reward consistent performance across contexts\n        avg_performance = sum(context_scores) / len(context_scores)\n        variance = sum((s - avg_performance) ** 2 for s in context_scores) / len(context_scores)\n        adaptability = avg_performance * (1 - min(0.5, variance))\n        return adaptability\n    \n    def _calculate_stability(self):\n        if len(self.recent_outcomes) < 5:\n            return 0.5\n        \n        outcomes = list(self.recent_outcomes)\n        variance = sum((x - sum(outcomes)/len(outcomes)) ** 2 for x in outcomes) / len(outcomes)\n        stability = 1.0 / (1 + 2 * variance)  # Lower variance = higher stability\n        return stability\n    \n    def record_outcome(self, success, tokens, context=None, execution_time=None, complexity=None):\n        if success:\n            self.successes += 1\n        else:\n            self.failures += 1\n            \n        self.total_tokens += tokens\n        self.recent_outcomes.append(1 if success else 0)\n        \n        if execution_time is not None:\n            self.execution_times.append(execution_time)\n        if complexity is not None:\n            self.complexity_scores.append(complexity)\n        \n        if context:\n            ctx_data = self.context_performance[context]\n            ctx_data[\'total\'] += 1\n            ctx_data[\'tokens\'] += tokens\n            if success:\n                ctx_data[\'success\'] += 1\n\ndef select_strategy(records, task_size=\'medium\', context=None, exploration_rate=0.12):\n    if not records:\n        return None\n    \n    # Enhanced exploration with contextual awareness\n    if random.random() < exploration_rate:\n        # Smart exploration: favor less-tested strategies in current context\n        exploration_weights = []\n        for record in records:\n            ctx_experience = 0\n            if context and context in record.context_performance:\n                ctx_experience = record.context_performance[context][\'total\']\n            \n            total_experience = record.successes + record.failures\n            exploration_weight = 1.0 / (1 + 0.3 * total_experience + 0.5 * ctx_experience)\n            exploration_weights.append(exploration_weight)\n        \n        return random.choices(records, weights=exploration_weights)[0]\n    \n    # Exploitation with multi-criteria selection\n    best_record = None\n    best_score = -1\n    \n    for record in records:\n        base_score = record.score\n        \n        # Context-specific adjustments\n        context_adjustment = 0\n        if context and context in record.context_performance:\n            ctx_data = record.context_performance[context]\n            if ctx_data[\'total\'] > 0:\n                ctx_success_rate = ctx_data[\'success\'] / ctx_data[\'total\']\n                context_adjustment = 0.1 * (ctx_success_rate - 0.5)\n        \n        # Task size compatibility (simple heuristic)\n        size_bonus = 0\n        avg_tokens = record.total_tokens / max(1, record.successes + record.failures)\n        if task_size == \'small\' and avg_tokens < 500:\n            size_bonus = 0.05\n        elif task_size == \'large\' and avg_tokens > 1500:\n            size_bonus = 0.05\n        \n        final_score = base_score + context_adjustment + size_bonus\n        \n        if final_score > best_score:\n            best_score = final_score\n            best_record = record\n    \n    return best_record\n\ndef create_adaptive_planner(strategy_names):\n    """Factory function to create a complete planning system"""\n    records = [StrategyRecord(name) for name in strategy_names]\n    \n    def plan_execution(task_context=None, task_size=\'medium\', exploration=0.12):\n        selected = select_strategy(records, task_size, task_context, exploration)\n        return selected.name if selected else strategy_names[0]\n    \n    def update_performance(strategy_name, success, tokens, context=None, **kwargs):\n        for record in records:\n            if record.name == strategy_name:\n                record.record_outcome(success, tokens, context, **kwargs)\n                break\n    \n    return plan_execution, update_performance, records'

PATTERN_HASH = "78e75c5499589bc7"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:strategy_selector_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class StrategySelectorGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Strategy Selector_gen1_gen2"""

    name = "strategy_selector_gen1_gen2"
    target_module = "orchestration.planner"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for strategy_selector_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "orchestration.planner"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.14993v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
