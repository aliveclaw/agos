"""Evolved strategy: Strategy Selector_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15809v1
Target module: orchestration.planner
Generated: 2026-02-18T08:03:38.429154
Defines: StrategyRecord, select_strategy, create_adaptive_planner
Code hash: eca0ab680ea9a756

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import math\nimport random\nfrom collections import defaultdict, deque\n\nclass StrategyRecord:\n    def __init__(self, name):\n        self.name = name\n        self.successes = 0\n        self.failures = 0\n        self.total_tokens = 0\n        self.recent_outcomes = deque(maxlen=15)\n        self.context_performance = defaultdict(lambda: {\'success\': 0, \'total\': 0, \'avg_tokens\': 0})\n        self.execution_times = deque(maxlen=20)\n        self.complexity_performance = defaultdict(lambda: {\'success\': 0, \'total\': 0})\n        self.last_used = 0\n        self.streak = 0\n        self.best_streak = 0\n    \n    @property\n    def score(self):\n        total = self.successes + self.failures\n        if total == 0: return 0.5\n        \n        # Enhanced success rate with adaptive confidence\n        success_rate = self.successes / total\n        confidence = min(1.0, math.log(1 + total) / math.log(21))  # Smoother confidence curve\n        base_score = success_rate * confidence + 0.5 * (1 - confidence)\n        \n        # Multi-factor efficiency scoring\n        avg_tokens = self.total_tokens / max(total, 1)\n        token_efficiency = 1.0 / (1 + math.log(1 + avg_tokens / 3000))\n        \n        # Velocity bonus for faster execution\n        velocity_bonus = 1.0\n        if self.execution_times:\n            avg_time = sum(self.execution_times) / len(self.execution_times)\n            velocity_bonus = min(1.3, 1.0 + (10.0 / max(avg_time, 1.0)) * 0.1)\n        \n        # Recent performance with momentum\n        recent_momentum = 1.0\n        if len(self.recent_outcomes) >= 3:\n            recent_window = list(self.recent_outcomes)[-7:]\n            recent_success = sum(recent_window) / len(recent_window)\n            momentum = recent_success / max(success_rate, 0.1)\n            recent_momentum = min(1.4, max(0.6, momentum))\n        \n        # Streak bonus for consistent performance\n        streak_bonus = min(1.2, 1.0 + (self.streak * 0.05))\n        \n        # Recency penalty to encourage exploration\n        recency_factor = max(0.9, 1.0 - (self.last_used * 0.02))\n        \n        final_score = (0.45 * base_score + \n                      0.2 * token_efficiency + \n                      0.15 * recent_momentum + \n                      0.1 * streak_bonus + \n                      0.1 * velocity_bonus) * recency_factor\n        \n        return round(min(1.0, final_score), 4)\n    \n    def update_outcome(self, success, tokens, context=None, complexity=1.0, execution_time=1.0):\n        if success:\n            self.successes += 1\n            self.streak += 1\n            self.best_streak = max(self.best_streak, self.streak)\n        else:\n            self.failures += 1\n            self.streak = 0\n            \n        self.total_tokens += tokens\n        self.recent_outcomes.append(1 if success else 0)\n        self.execution_times.append(execution_time)\n        self.last_used = 0  # Reset recency counter\n        \n        if context:\n            ctx_perf = self.context_performance[context]\n            ctx_perf[\'total\'] += 1\n            if success:\n                ctx_perf[\'success\'] += 1\n            ctx_perf[\'avg_tokens\'] = (ctx_perf[\'avg_tokens\'] * (ctx_perf[\'total\'] - 1) + tokens) / ctx_perf[\'total\']\n        \n        # Track complexity-specific performance\n        complexity_key = f"c_{int(complexity * 10)}"\n        self.complexity_performance[complexity_key][\'total\'] += 1\n        if success:\n            self.complexity_performance[complexity_key][\'success\'] += 1\n\ndef select_strategy(records, task_size=\'medium\', context=None, complexity=1.0, exploration_rate=0.15):\n    if not records:\n        return None\n    \n    # Age all strategies\n    for record in records.values():\n        record.last_used += 1\n    \n    # Context-aware scoring\n    scored_strategies = []\n    for name, record in records.items():\n        base_score = record.score\n        \n        # Context compatibility boost\n        context_boost = 1.0\n        if context and context in record.context_performance:\n            ctx_perf = record.context_performance[context]\n            if ctx_perf[\'total\'] > 0:\n                ctx_success_rate = ctx_perf[\'success\'] / ctx_perf[\'total\']\n                context_boost = min(1.3, 0.8 + ctx_success_rate * 0.5)\n        \n        # Complexity matching\n        complexity_boost = 1.0\n        complexity_key = f"c_{int(complexity * 10)}"\n        if complexity_key in record.complexity_performance:\n            comp_perf = record.complexity_performance[complexity_key]\n            if comp_perf[\'total\'] > 0:\n                comp_success_rate = comp_perf[\'success\'] / comp_perf[\'total\']\n                complexity_boost = min(1.25, 0.9 + comp_success_rate * 0.35)\n        \n        # Task size preference\n        size_multiplier = {\n            \'small\': 1.1 if record.total_tokens / max(record.successes + record.failures, 1) < 2000 else 0.95,\n            \'medium\': 1.0,\n            \'large\': 1.1 if record.total_tokens / max(record.successes + record.failures, 1) > 4000 else 0.95\n        }.get(task_size, 1.0)\n        \n        adjusted_score = base_score * context_boost * complexity_boost * size_multiplier\n        scored_strategies.append((name, adjusted_score, record))\n    \n    # Sort by adjusted score\n    scored_strategies.sort(key=lambda x: x[1], reverse=True)\n    \n    # Epsilon-greedy selection with adaptive exploration\n    if random.random() < exploration_rate:\n        # Weighted random selection favoring underexplored strategies\n        weights = []\n        for name, score, record in scored_strategies:\n            total_attempts = record.successes + record.failures\n            exploration_weight = 1.0 / (1 + total_attempts * 0.1)  # Favor less tried strategies\n            weights.append(exploration_weight)\n        \n        total_weight = sum(weights)\n        if total_weight > 0:\n            rand_val = random.random() * total_weight\n            cumulative = 0\n            for i, weight in enumerate(weights):\n                cumulative += weight\n                if rand_val <= cumulative:\n                    return scored_strategies[i][0]\n    \n    # Return best strategy\n    return scored_strategies[0][0] if scored_strategies else None\n\ndef create_adaptive_planner(strategy_names):\n    """Factory function to create a planner with multiple strategies"""\n    records = {name: StrategyRecord(name) for name in strategy_names}\n    \n    def plan_execution(task_size=\'medium\', context=None, complexity=1.0):\n        selected = select_strategy(records, task_size, context, complexity)\n        return {\n            \'strategy\': selected,\n            \'records\': records,\n            \'confidence\': records[selected].score if selected else 0.5\n        }\n    \n    return plan_execution, records'

PATTERN_HASH = "eca0ab680ea9a756"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:strategy_selector_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class StrategySelectorGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Strategy Selector_gen1_gen2"""

    name = "strategy_selector_gen1_gen2"
    target_module = "orchestration.planner"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for strategy_selector_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "orchestration.planner"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15809v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
