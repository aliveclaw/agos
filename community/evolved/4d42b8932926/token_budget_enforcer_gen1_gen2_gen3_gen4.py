"""Evolved strategy: Token Budget Enforcer_gen1_gen2_gen3_gen4

Auto-generated by agos evolution engine.
Source paper: 2602.15830v1
Target module: policy
Generated: 2026-02-18T08:26:58.546091
Defines: AdaptiveTokenBudget
Code hash: 3df24c1ea75d9702

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = "import time\nimport math\nfrom collections import deque\nimport random\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.0, window_size=20):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.5\n        self.adaptation_factor = 0.15\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        self.load_predictor = deque(maxlen=8)\n        self.congestion_threshold = 0.75\n        self.recovery_factor = 0.9\n        self.priority_weights = {'size': 0.4, 'urgency': 0.3, 'history': 0.3}\n        \n    def _calculate_priority(self, tokens, urgency=0.5, request_type='normal'):\n        current_time = time.time()\n        recent_requests = [r for r in self.request_history if current_time - r['timestamp'] < 2.0]\n        \n        # Size-based priority (smaller requests get higher priority during congestion)\n        utilization = self.used / self.limit if self.limit > 0 else 0\n        if utilization > self.congestion_threshold:\n            size_priority = max(0.2, 1.0 - (tokens / self.base_limit))\n        else:\n            size_priority = 0.8\n            \n        # Urgency factor\n        urgency_priority = min(1.0, max(0.1, urgency))\n        \n        # Historical performance factor\n        success_rate = self.success_streak / max(1, self.success_streak + self.violation_streak)\n        history_priority = 0.5 + (success_rate * 0.5)\n        \n        # Request type modifier\n        type_modifier = 1.2 if request_type == 'critical' else 1.0\n        \n        weighted_priority = (\n            self.priority_weights['size'] * size_priority +\n            self.priority_weights['urgency'] * urgency_priority +\n            self.priority_weights['history'] * history_priority\n        ) * type_modifier\n        \n        return min(1.0, weighted_priority)\n    \n    def _get_effective_limit(self):\n        current_time = time.time()\n        \n        # Update load predictor\n        if len(self.request_history) >= 3:\n            recent_usage = sum(r['tokens'] for r in list(self.request_history)[-3:] if r['granted'])\n            self.load_predictor.append(recent_usage)\n        \n        # Calculate trend and adapt limit\n        base_limit = self.base_limit\n        if len(self.load_predictor) >= 3:\n            recent_avg = sum(list(self.load_predictor)[-3:]) / 3\n            older_avg = sum(list(self.load_predictor)[:-3]) / max(1, len(self.load_predictor) - 3)\n            \n            trend_factor = recent_avg / max(1, older_avg)\n            \n            if trend_factor > 1.2:  # Increasing load\n                adaptive_limit = int(base_limit * 0.85)\n            elif trend_factor < 0.8:  # Decreasing load\n                adaptive_limit = int(base_limit * 1.15)\n            else:\n                adaptive_limit = base_limit\n        else:\n            adaptive_limit = base_limit\n            \n        # Apply efficiency-based adjustment\n        efficiency_multiplier = 0.8 + (self.efficiency_score * 0.4)\n        final_limit = int(adaptive_limit * efficiency_multiplier)\n        \n        return max(int(base_limit * 0.5), min(self.burst_limit, final_limit))\n    \n    def _auto_decay(self):\n        current_time = time.time()\n        if current_time - self.last_decay >= self.auto_decay_interval:\n            # Exponential decay with efficiency consideration\n            decay_rate = 0.3 * (2.0 - self.efficiency_score)\n            decay_amount = max(1, int(self.used * decay_rate))\n            self.used = max(0, self.used - decay_amount)\n            self.last_decay = current_time\n            \n            # Update efficiency score\n            self._update_efficiency()\n    \n    def _update_efficiency(self):\n        if len(self.request_history) >= 5:\n            recent_requests = list(self.request_history)[-5:]\n            granted = sum(1 for r in recent_requests if r['granted'])\n            total = len(recent_requests)\n            \n            current_efficiency = granted / total if total > 0 else 1.0\n            \n            # Smooth efficiency score update\n            self.efficiency_score = (self.efficiency_score * 0.7) + (current_efficiency * 0.3)\n    \n    def request_tokens(self, tokens, urgency=0.5, request_type='normal'):\n        self._auto_decay()\n        \n        current_time = time.time()\n        effective_limit = self._get_effective_limit()\n        priority = self._calculate_priority(tokens, urgency, request_type)\n        \n        # Priority-based allocation\n        priority_threshold = 0.3\n        can_grant = False\n        \n        if priority >= priority_threshold:\n            if self.used + tokens <= effective_limit:\n                can_grant = True\n            elif self.used + tokens <= self.burst_limit and priority > 0.7:\n                can_grant = True\n        \n        # Grant or deny request\n        if can_grant:\n            self.used += tokens\n            self.peak_usage = max(self.peak_usage, self.used)\n            self.success_streak += 1\n            self.violation_streak = 0\n            granted = True\n        else:\n            self.violations += 1\n            self.violation_streak += 1\n            self.success_streak = 0\n            granted = False\n        \n        # Record request\n        self.request_history.append({\n            'timestamp': current_time,\n            'tokens': tokens,\n            'granted': granted,\n            'priority': priority,\n            'urgency': urgency,\n            'type': request_type\n        })\n        \n        return granted\n    \n    def get_status(self):\n        utilization = self.used / self.limit if self.limit > 0 else 0\n        return {\n            'used': self.used,\n            'limit': self.limit,\n            'effective_limit': self._get_effective_limit(),\n            'utilization': utilization,\n            'violations': self.violations,\n            'efficiency': self.efficiency_score,\n            'peak_usage': self.peak_usage,\n            'success_streak': self.success_streak\n        }\n    \n    def reset(self):\n        self.used = 0\n        self.violations = 0\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        self.request_history.clear()\n        self.load_predictor.clear()"

PATTERN_HASH = "3df24c1ea75d9702"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:token_budget_enforcer_gen1_gen2_gen3_gen4>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class TokenBudgetEnforcerGen1Gen2Gen3Gen4Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Token Budget Enforcer_gen1_gen2_gen3_gen4"""

    name = "token_budget_enforcer_gen1_gen2_gen3_gen4"
    target_module = "policy"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for token_budget_enforcer_gen1_gen2_gen3_gen4: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "policy"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15830v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
