"""Evolved strategy: Token Budget Enforcer_gen1_gen2_gen3

Auto-generated by agos evolution engine.
Source paper: 2602.15830v1
Target module: policy
Generated: 2026-02-18T09:07:42.149999
Defines: AdaptiveTokenBudget
Code hash: 7487392260a1dc72

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = "import time\nimport math\nfrom collections import deque\nimport random\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.5, window_size=30):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.3\n        self.adaptation_factor = 0.12\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        self.load_factor = 0.0\n        self.prediction_buffer = deque(maxlen=10)\n        \n    def _calculate_priority(self, tokens):\n        current_time = time.time()\n        recent_requests = [r for r in self.request_history \n                          if current_time - r['timestamp'] < 1.0]\n        \n        # Higher priority for smaller requests during high load\n        size_factor = max(0.1, 1.0 - (tokens / self.base_limit))\n        \n        # Priority boost during low activity periods\n        activity_factor = max(0.3, 1.0 - (len(recent_requests) / 10))\n        \n        # Historical success rate influence\n        success_rate = self._get_recent_success_rate()\n        history_factor = 0.5 + (success_rate * 0.5)\n        \n        return min(1.0, size_factor * activity_factor * history_factor)\n    \n    def _get_recent_success_rate(self):\n        if not self.request_history:\n            return 1.0\n        recent = list(self.request_history)[-10:]\n        granted = sum(1 for r in recent if r['granted'])\n        return granted / len(recent) if recent else 1.0\n    \n    def _predict_load(self):\n        if len(self.request_history) < 5:\n            return self.load_factor\n            \n        recent_usage = [r['tokens'] for r in list(self.request_history)[-5:]]\n        trend = sum(recent_usage) / len(recent_usage)\n        predicted_load = trend / self.base_limit\n        \n        self.prediction_buffer.append(predicted_load)\n        return sum(self.prediction_buffer) / len(self.prediction_buffer)\n    \n    def _get_effective_limit(self):\n        predicted_load = self._predict_load()\n        self.load_factor = predicted_load\n        \n        # Adaptive limit based on recent performance\n        if self.efficiency_score > 0.8 and self.violation_streak == 0:\n            # Increase limit during good performance\n            multiplier = 1.0 + (self.efficiency_score - 0.8) * 0.5\n        elif self.violation_streak > 2:\n            # Decrease limit during violations\n            multiplier = max(0.6, 1.0 - (self.violation_streak * 0.1))\n        else:\n            multiplier = 1.0\n            \n        # Load-based adjustment\n        if predicted_load > 0.8:\n            multiplier *= 0.9\n        elif predicted_load < 0.4:\n            multiplier *= 1.1\n            \n        return int(self.base_limit * multiplier)\n    \n    def _auto_decay(self):\n        now = time.time()\n        if now - self.last_decay >= self.auto_decay_interval:\n            elapsed = now - self.last_decay\n            \n            # Adaptive decay rate based on load\n            decay_rate = 0.3 + (self.load_factor * 0.4)\n            decay_amount = int(self.used * decay_rate * (elapsed / self.auto_decay_interval))\n            \n            self.used = max(0, self.used - decay_amount)\n            self.last_decay = now\n    \n    def _adapt_on_violation(self):\n        # More aggressive adaptation on repeated violations\n        penalty = min(0.3, self.violation_streak * 0.05)\n        self.efficiency_score = max(0.1, self.efficiency_score - penalty)\n        \n        # Reduce limit temporarily\n        if self.violation_streak > 3:\n            self.limit = max(int(self.base_limit * 0.7), self.limit - int(self.base_limit * 0.1))\n    \n    def _adapt_on_success(self):\n        # Gradual recovery\n        if self.success_streak > 5:\n            recovery = min(0.1, self.success_streak * 0.01)\n            self.efficiency_score = min(1.0, self.efficiency_score + recovery)\n            \n            # Gradually restore limit\n            if self.limit < self.base_limit:\n                self.limit = min(self.base_limit, self.limit + int(self.base_limit * 0.05))\n    \n    def _update_efficiency(self):\n        if len(self.request_history) >= 10:\n            recent_requests = list(self.request_history)[-10:]\n            success_rate = sum(1 for r in recent_requests if r['granted']) / len(recent_requests)\n            utilization = self.used / self.base_limit\n            \n            # Balance success rate and utilization\n            self.efficiency_score = (success_rate * 0.7) + (min(utilization, 1.0) * 0.3)\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Enhanced priority calculation\n        priority = self._calculate_priority(tokens)\n        request_data = {\n            'tokens': tokens,\n            'timestamp': time.time(),\n            'granted': False,\n            'priority': priority\n        }\n        \n        # Smart effective limit calculation\n        effective_limit = self._get_effective_limit()\n        \n        # Multi-tier admission control\n        if self.used + tokens > effective_limit:\n            # Tier 1: High priority with burst capacity\n            if priority > 0.8 and self.used + tokens <= self.burst_limit:\n                pass\n            # Tier 2: Medium priority with partial burst\n            elif priority > 0.6 and self.used + tokens <= int(effective_limit * 1.2):\n                pass\n            # Tier 3: Reject\n            else:\n                self.violations += 1\n                self.violation_streak += 1\n                self.success_streak = 0\n                self._adapt_on_violation()\n                self.request_history.append(request_data)\n                return False\n        \n        self.used += tokens\n        self.peak_usage = max(self.peak_usage, self.used)\n        self.success_streak += 1\n        self.violation_streak = 0\n        request_data['granted'] = True\n        self.request_history.append(request_data)\n        self._adapt_on_success()\n        self._update_efficiency()\n        return True\n    \n    def get_status(self):\n        return {\n            'used': self.used,\n            'limit': self.limit,\n            'effective_limit': self._get_effective_limit(),\n            'efficiency': self.efficiency_score,\n            'load_factor': self.load_factor,\n            'violations': self.violations\n        }"

PATTERN_HASH = "7487392260a1dc72"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:token_budget_enforcer_gen1_gen2_gen3>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class TokenBudgetEnforcerGen1Gen2Gen3Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Token Budget Enforcer_gen1_gen2_gen3"""

    name = "token_budget_enforcer_gen1_gen2_gen3"
    target_module = "policy"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for token_budget_enforcer_gen1_gen2_gen3: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "policy"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15830v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
