"""Evolved strategy: Softmax Diversity Scorer_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15021v1
Target module: knowledge.semantic
Generated: 2026-02-18T09:17:01.401401
Defines: SemanticScorer
Code hash: 6609cf3ecd515100

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import math\nimport random\nfrom collections import defaultdict, deque\nimport json\n\nclass SemanticScorer:\n    def __init__(self, temperature=0.3, diversity_weight=0.2, memory_size=100):\n        self.temperature = max(temperature, 0.01)\n        self.diversity_weight = diversity_weight\n        self.history = defaultdict(float)\n        self.recent_selections = deque(maxlen=memory_size)\n        self.context_embeddings = {}\n        self.semantic_clusters = defaultdict(set)\n        self.decay_factor = 0.95\n        \n    def softmax_score(self, values, labels=None, context=None):\n        if not values: return []\n        \n        # Apply temperature scaling with context awareness\n        temp = self._adaptive_temperature(context)\n        exp_vals = [math.exp(v / temp) for v in values]\n        total = sum(exp_vals)\n        base_scores = [v / total for v in exp_vals]\n        \n        if labels and len(labels) == len(values):\n            # Multi-factor scoring\n            diversity_bonus = self._calculate_diversity_bonus(labels)\n            semantic_bonus = self._calculate_semantic_bonus(labels, context)\n            recency_penalty = self._calculate_recency_penalty(labels)\n            \n            adjusted_scores = []\n            for i, score in enumerate(base_scores):\n                label = labels[i]\n                diversity_mult = 1 + self.diversity_weight * diversity_bonus.get(label, 0)\n                semantic_mult = 1 + 0.15 * semantic_bonus.get(label, 0)\n                recency_mult = 1 - 0.1 * recency_penalty.get(label, 0)\n                \n                final_score = score * diversity_mult * semantic_mult * recency_mult\n                adjusted_scores.append(max(final_score, 0.001))  # Prevent zero scores\n            \n            # Renormalize with smoothing\n            total_adjusted = sum(adjusted_scores)\n            return [s / total_adjusted for s in adjusted_scores]\n        \n        return base_scores\n    \n    def _adaptive_temperature(self, context=None):\n        # Calculate entropy of recent selections\n        if len(self.recent_selections) < 2:\n            return self.temperature\n            \n        freq_dist = defaultdict(int)\n        for selection in self.recent_selections:\n            freq_dist[selection] += 1\n            \n        total = len(self.recent_selections)\n        entropy = -sum((count/total) * math.log2(count/total) \n                      for count in freq_dist.values() if count > 0)\n        \n        # Context-aware temperature adjustment\n        context_factor = 1.0\n        if context and hasattr(context, \'uncertainty\'):\n            context_factor = 1 + context.uncertainty * 0.3\n            \n        base_temp = 0.2 + entropy * 0.25\n        return max(0.05, min(1.2, base_temp * context_factor))\n    \n    def _calculate_diversity_bonus(self, labels):\n        bonus = {}\n        total_selections = sum(self.history.values()) + 1\n        \n        for label in set(labels):\n            frequency = self.history[label]\n            # Inverse frequency with logarithmic smoothing\n            normalized_freq = frequency / total_selections\n            bonus[label] = math.log(1 + 1/(normalized_freq + 0.01))\n        \n        return bonus\n    \n    def _calculate_semantic_bonus(self, labels, context):\n        if not context:\n            return {label: 0 for label in labels}\n            \n        bonus = {}\n        context_vector = self._extract_context_features(context)\n        \n        for label in set(labels):\n            if label in self.context_embeddings:\n                similarity = self._cosine_similarity(\n                    context_vector, \n                    self.context_embeddings[label]\n                )\n                bonus[label] = similarity\n            else:\n                bonus[label] = 0\n                \n        return bonus\n    \n    def _calculate_recency_penalty(self, labels):\n        penalty = {}\n        recent_items = list(self.recent_selections)[-10:]  # Last 10 selections\n        \n        for label in set(labels):\n            recent_count = recent_items.count(label)\n            penalty[label] = min(recent_count * 0.2, 0.8)  # Cap penalty\n            \n        return penalty\n    \n    def _extract_context_features(self, context):\n        # Simple feature extraction from context\n        if isinstance(context, str):\n            # Hash-based feature vector\n            features = [0.0] * 8\n            for i, char in enumerate(context[:8]):\n                features[i] = ord(char) / 255.0\n            return features\n        elif isinstance(context, dict):\n            # Extract numerical features\n            return [float(hash(str(v)) % 1000) / 1000.0 \n                   for v in list(context.values())[:8]]\n        return [0.5] * 8  # Default neutral vector\n    \n    def _cosine_similarity(self, vec1, vec2):\n        if len(vec1) != len(vec2):\n            return 0.0\n            \n        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n        norm1 = math.sqrt(sum(a * a for a in vec1))\n        norm2 = math.sqrt(sum(b * b for b in vec2))\n        \n        if norm1 == 0 or norm2 == 0:\n            return 0.0\n            \n        return dot_product / (norm1 * norm2)\n    \n    def update_selection(self, selected_label, context=None):\n        # Decay historical frequencies\n        for label in self.history:\n            self.history[label] *= self.decay_factor\n            \n        self.history[selected_label] += 1\n        self.recent_selections.append(selected_label)\n        \n        # Update context embeddings\n        if context:\n            context_vector = self._extract_context_features(context)\n            if selected_label in self.context_embeddings:\n                # Exponential moving average\n                old_vec = self.context_embeddings[selected_label]\n                alpha = 0.3\n                new_vec = [alpha * new + (1-alpha) * old \n                          for new, old in zip(context_vector, old_vec)]\n                self.context_embeddings[selected_label] = new_vec\n            else:\n                self.context_embeddings[selected_label] = context_vector\n    \n    def get_exploration_candidates(self, labels, top_k=3):\n        """Identify labels that should be explored more"""\n        total_selections = sum(self.history.values()) + 1\n        exploration_scores = {}\n        \n        for label in labels:\n            frequency = self.history[label]\n            exploration_score = 1.0 / (frequency + 1)  # Inverse frequency\n            exploration_scores[label] = exploration_score\n            \n        return sorted(exploration_scores.items(), \n                     key=lambda x: x[1], reverse=True)[:top_k]\n\n# Test the enhanced semantic scorer\nscorer = SemanticScorer()\nvalues = [0.9, 0.7, 0.4, 0.2, 0.1]\nlabels = [\'concept_A\', \'concept_B\', \'concept_C\', \'concept_D\', \'concept_E\']\ncontext = {"task": "classification", "domain": "nlp", "uncertainty": 0.3}\n\nscores = scorer.softmax_score(values, labels, context)\nassert abs(sum(scores) - 1.0) < 0.001\n\n# Test exploration candidates\ncandidates = scorer.get_exploration_candidates(labels)\nassert len(candidates) <= 3'

PATTERN_HASH = "6609cf3ecd515100"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:softmax_diversity_scorer_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class SoftmaxDiversityScorerGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Softmax Diversity Scorer_gen1_gen2"""

    name = "softmax_diversity_scorer_gen1_gen2"
    target_module = "knowledge.semantic"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for softmax_diversity_scorer_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.semantic"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15021v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
