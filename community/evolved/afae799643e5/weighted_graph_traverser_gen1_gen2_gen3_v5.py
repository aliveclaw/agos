"""Evolved strategy: Weighted Graph Traverser_gen1_gen2_gen3

Auto-generated by agos evolution engine.
Source paper: 2602.15791v1
Target module: knowledge.graph
Generated: 2026-02-18T09:07:08.599954
Defines: KnowledgeGraph
Code hash: d3562359b4744aa1

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = "from collections import defaultdict, deque\nimport math\nimport json\nimport heapq\n\nclass KnowledgeGraph:\n    def __init__(self):\n        self.edges = defaultdict(list)\n        self.reverse_edges = defaultdict(list)\n        self.node_weights = defaultdict(lambda: 1.0)\n        self.relation_types = set()\n        self.node_metadata = defaultdict(dict)\n        self.relation_weights = defaultdict(lambda: 1.0)\n        self.node_embeddings = {}\n        self.clusters = defaultdict(set)\n        self.temporal_edges = defaultdict(list)\n    \n    def add(self, src, rel, dst, weight=1.0, bidirectional=False, metadata=None, timestamp=None):\n        edge_data = (dst, rel, weight, timestamp)\n        self.edges[src].append(edge_data)\n        self.reverse_edges[dst].append((src, rel, weight, timestamp))\n        self.relation_types.add(rel)\n        \n        if timestamp:\n            self.temporal_edges[timestamp].append((src, rel, dst, weight))\n        \n        if metadata:\n            self.node_metadata[src].update(metadata.get('src', {}))\n            self.node_metadata[dst].update(metadata.get('dst', {}))\n        \n        if bidirectional:\n            self.edges[dst].append((src, rel, weight, timestamp))\n            self.reverse_edges[src].append((dst, rel, weight, timestamp))\n    \n    def set_node_weight(self, node, weight):\n        self.node_weights[node] = weight\n    \n    def set_relation_weight(self, relation, weight):\n        self.relation_weights[relation] = weight\n    \n    def set_node_embedding(self, node, embedding):\n        self.node_embeddings[node] = embedding\n    \n    def add_to_cluster(self, cluster_id, node):\n        self.clusters[cluster_id].add(node)\n    \n    def traverse(self, start, max_depth=3, decay=0.7, min_score=0.01, relation_filter=None, boost_nodes=None, temporal_window=None):\n        visited = {}\n        queue = deque([(start, 1.0, 0, [start])])\n        boost_nodes = boost_nodes or set()\n        \n        while queue:\n            node, score, depth, path = queue.popleft()\n            \n            if node in visited and visited[node] >= score:\n                continue\n            if depth > max_depth or score < min_score:\n                continue\n            \n            node_boost = 1.5 if node in boost_nodes else 1.0\n            final_score = score * self.node_weights[node] * node_boost\n            visited[node] = round(final_score, 4)\n            \n            for edge_data in self.edges.get(node, []):\n                dst, rel, w = edge_data[0], edge_data[1], edge_data[2]\n                timestamp = edge_data[3] if len(edge_data) > 3 else None\n                \n                if dst in path:\n                    continue\n                if relation_filter and rel not in relation_filter:\n                    continue\n                if temporal_window and timestamp and not (temporal_window[0] <= timestamp <= temporal_window[1]):\n                    continue\n                \n                rel_weight = self.relation_weights[rel]\n                new_score = score * decay * w * rel_weight\n                \n                if new_score >= min_score:\n                    queue.append((dst, new_score, depth + 1, path + [dst]))\n        \n        return dict(sorted(visited.items(), key=lambda x: x[1], reverse=True))\n    \n    def shortest_path(self, start, end, relation_filter=None):\n        if start == end:\n            return [start]\n        \n        queue = deque([(start, [start])])\n        visited = {start}\n        \n        while queue:\n            node, path = queue.popleft()\n            \n            for edge_data in self.edges.get(node, []):\n                dst, rel = edge_data[0], edge_data[1]\n                \n                if dst in visited:\n                    continue\n                if relation_filter and rel not in relation_filter:\n                    continue\n                \n                new_path = path + [dst]\n                if dst == end:\n                    return new_path\n                \n                visited.add(dst)\n                queue.append((dst, new_path))\n        \n        return None\n    \n    def find_similar_nodes(self, node, threshold=0.8, max_results=10):\n        if node not in self.node_embeddings:\n            return []\n        \n        target_embedding = self.node_embeddings[node]\n        similarities = []\n        \n        for other_node, embedding in self.node_embeddings.items():\n            if other_node == node:\n                continue\n            \n            similarity = self._cosine_similarity(target_embedding, embedding)\n            if similarity >= threshold:\n                similarities.append((other_node, similarity))\n        \n        similarities.sort(key=lambda x: x[1], reverse=True)\n        return similarities[:max_results]\n    \n    def _cosine_similarity(self, vec1, vec2):\n        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n        magnitude1 = math.sqrt(sum(a * a for a in vec1))\n        magnitude2 = math.sqrt(sum(b * b for b in vec2))\n        \n        if magnitude1 == 0 or magnitude2 == 0:\n            return 0\n        \n        return dot_product / (magnitude1 * magnitude2)\n    \n    def get_node_importance(self, node):\n        in_degree = len(self.reverse_edges[node])\n        out_degree = len(self.edges[node])\n        base_weight = self.node_weights[node]\n        \n        # PageRank-like importance calculation\n        importance = base_weight * (1 + math.log(1 + in_degree + out_degree))\n        return round(importance, 4)\n    \n    def export_subgraph(self, nodes):\n        subgraph = KnowledgeGraph()\n        \n        for node in nodes:\n            if node in self.node_weights:\n                subgraph.set_node_weight(node, self.node_weights[node])\n            if node in self.node_metadata:\n                subgraph.node_metadata[node] = self.node_metadata[node].copy()\n            if node in self.node_embeddings:\n                subgraph.set_node_embedding(node, self.node_embeddings[node])\n        \n        for src in nodes:\n            for edge_data in self.edges.get(src, []):\n                dst = edge_data[0]\n                if dst in nodes:\n                    rel, weight = edge_data[1], edge_data[2]\n                    timestamp = edge_data[3] if len(edge_data) > 3 else None\n                    subgraph.add(src, rel, dst, weight, timestamp=timestamp)\n        \n        return subgraph\n    \n    def to_dict(self):\n        return {\n            'edges': dict(self.edges),\n            'node_weights': dict(self.node_weights),\n            'relation_types': list(self.relation_types),\n            'node_metadata': dict(self.node_metadata),\n            'relation_weights': dict(self.relation_weights),\n            'clusters': {k: list(v) for k, v in self.clusters.items()}\n        }"

PATTERN_HASH = "d3562359b4744aa1"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:weighted_graph_traverser_gen1_gen2_gen3>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class WeightedGraphTraverserGen1Gen2Gen3Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Weighted Graph Traverser_gen1_gen2_gen3"""

    name = "weighted_graph_traverser_gen1_gen2_gen3"
    target_module = "knowledge.graph"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for weighted_graph_traverser_gen1_gen2_gen3: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "knowledge.graph"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15791v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
