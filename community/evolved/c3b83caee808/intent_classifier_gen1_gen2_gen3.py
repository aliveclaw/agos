"""Evolved strategy: Intent Classifier_gen1_gen2_gen3

Auto-generated by agos evolution engine.
Source paper: 2602.15001v1
Target module: intent
Generated: 2026-02-18T08:39:52.640420
Defines: IntentClassifier, create_intent_classifier
Code hash: 210ae59e07bed885

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import re\nimport math\nfrom collections import defaultdict, Counter\nfrom typing import Dict, List, Tuple, Optional, Set\n\nclass IntentClassifier:\n    def __init__(self):\n        self.intent_patterns = {\n            \'research\': {\n                \'keywords\': [\'search\', \'find\', \'lookup\', \'investigate\', \'analyze\', \'study\', \'explore\', \'discover\', \'examine\', \'research\', \'query\', \'retrieve\'],\n                \'patterns\': [r\'\\b(search|find|look\\s*up|investigate|analyze|study|explore|discover|examine|research|query|retrieve)\\b\'],\n                \'context\': [\'papers\', \'information\', \'data\', \'knowledge\', \'facts\', \'evidence\', \'documentation\', \'sources\'],\n                \'weight\': 1.0,\n                \'negatives\': [\'implement\', \'build\', \'create\']\n            },\n            \'code\': {\n                \'keywords\': [\'write\', \'implement\', \'fix\', \'refactor\', \'build\', \'create\', \'develop\', \'program\', \'code\', \'debug\', \'compile\', \'deploy\'],\n                \'patterns\': [r\'\\b(write|implement|fix|refactor|build|create|develop|program|code|debug|compile|deploy)\\b\', r\'\\b(function|class|method|api)\\b\'],\n                \'context\': [\'function\', \'class\', \'method\', \'script\', \'application\', \'program\', \'algorithm\', \'library\', \'framework\'],\n                \'weight\': 1.3,\n                \'negatives\': [\'review\', \'analyze\', \'search\']\n            },\n            \'review\': {\n                \'keywords\': [\'review\', \'check\', \'audit\', \'inspect\', \'validate\', \'verify\', \'assess\', \'evaluate\', \'examine\', \'test\'],\n                \'patterns\': [r\'\\b(review|check|audit|inspect|validate|verify|assess|evaluate|examine|test)\\b\'],\n                \'context\': [\'logs\', \'code\', \'security\', \'quality\', \'compliance\', \'standards\', \'performance\', \'results\'],\n                \'weight\': 0.9,\n                \'negatives\': [\'create\', \'build\', \'implement\']\n            },\n            \'monitor\': {\n                \'keywords\': [\'watch\', \'track\', \'alert\', \'detect\', \'observe\', \'monitor\', \'supervise\', \'guard\', \'scan\'],\n                \'patterns\': [r\'\\b(watch|track|alert|detect|observe|monitor|supervise|guard|scan)\\b\', r\'\\bfor\\s+(anomalies|errors|issues|changes)\\b\'],\n                \'context\': [\'anomalies\', \'errors\', \'performance\', \'metrics\', \'status\', \'health\', \'system\', \'network\'],\n                \'weight\': 1.1,\n                \'negatives\': [\'create\', \'build\']\n            },\n            \'automate\': {\n                \'keywords\': [\'schedule\', \'trigger\', \'automate\', \'repeat\', \'cron\', \'batch\', \'pipeline\', \'workflow\'],\n                \'patterns\': [r\'\\b(schedule|trigger|automate|repeat|cron|batch|pipeline|workflow)\\b\', r\'\\bevery\\s+\\d+\'],\n                \'context\': [\'task\', \'job\', \'process\', \'routine\', \'interval\', \'periodic\'],\n                \'weight\': 1.2,\n                \'negatives\': [\'manual\', \'interactive\']\n            }\n        }\n        self.confidence_threshold = 0.3\n        self.word_cache = {}\n        \n    def preprocess_text(self, text: str) -> str:\n        """Clean and normalize input text"""\n        text = text.lower().strip()\n        text = re.sub(r\'[^\\w\\s]\', \' \', text)\n        text = re.sub(r\'\\s+\', \' \', text)\n        return text\n    \n    def extract_features(self, text: str) -> Dict[str, float]:\n        """Extract weighted features from text"""\n        features = defaultdict(float)\n        words = text.split()\n        word_count = len(words)\n        \n        if word_count == 0:\n            return features\n            \n        # Create n-grams for better context\n        ngrams = []\n        for i in range(len(words)):\n            ngrams.append(words[i])\n            if i < len(words) - 1:\n                ngrams.append(f"{words[i]} {words[i+1]}")\n        \n        for intent, config in self.intent_patterns.items():\n            score = 0.0\n            \n            # Keyword matching with position weighting\n            for i, word in enumerate(words):\n                if word in config[\'keywords\']:\n                    position_weight = 1.0 + (0.5 if i < 3 else 0.0)  # Boost early words\n                    score += position_weight\n            \n            # Pattern matching\n            for pattern in config[\'patterns\']:\n                matches = len(re.findall(pattern, text, re.IGNORECASE))\n                score += matches * 1.5\n            \n            # Context matching\n            context_matches = sum(1 for ctx in config[\'context\'] if ctx in text)\n            score += context_matches * 0.8\n            \n            # Negative keyword penalty\n            if \'negatives\' in config:\n                negative_matches = sum(1 for neg in config[\'negatives\'] if neg in text)\n                score -= negative_matches * 0.5\n            \n            # Normalize by text length and apply intent weight\n            normalized_score = (score / math.sqrt(word_count)) * config[\'weight\']\n            features[intent] = max(0, normalized_score)\n            \n        return features\n    \n    def classify_intent(self, text: str) -> Tuple[str, float, Dict[str, float]]:\n        """Classify intent with confidence score and all scores"""\n        if not text or not text.strip():\n            return \'unknown\', 0.0, {}\n            \n        processed_text = self.preprocess_text(text)\n        features = self.extract_features(processed_text)\n        \n        if not features:\n            return \'unknown\', 0.0, {}\n        \n        # Find best intent\n        best_intent = max(features.keys(), key=lambda k: features[k])\n        best_score = features[best_intent]\n        \n        # Calculate confidence based on score separation\n        sorted_scores = sorted(features.values(), reverse=True)\n        if len(sorted_scores) > 1 and sorted_scores[0] > 0:\n            confidence = min(1.0, best_score / max(0.1, sum(sorted_scores)))\n        else:\n            confidence = best_score if best_score > 0 else 0.0\n        \n        # Apply confidence threshold\n        if confidence < self.confidence_threshold:\n            return \'unknown\', confidence, dict(features)\n            \n        return best_intent, confidence, dict(features)\n    \n    def batch_classify(self, texts: List[str]) -> List[Tuple[str, float, Dict[str, float]]]:\n        """Classify multiple texts efficiently"""\n        return [self.classify_intent(text) for text in texts]\n    \n    def get_intent_suggestions(self, text: str, top_k: int = 3) -> List[Tuple[str, float]]:\n        """Get top-k intent suggestions with scores"""\n        _, _, all_scores = self.classify_intent(text)\n        sorted_intents = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)\n        return sorted_intents[:top_k]\n    \n    def update_confidence_threshold(self, threshold: float):\n        """Dynamically adjust confidence threshold"""\n        self.confidence_threshold = max(0.0, min(1.0, threshold))\n\ndef create_intent_classifier() -> IntentClassifier:\n    """Factory function to create configured intent classifier"""\n    return IntentClassifier()'

PATTERN_HASH = "210ae59e07bed885"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:intent_classifier_gen1_gen2_gen3>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class IntentClassifierGen1Gen2Gen3Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Intent Classifier_gen1_gen2_gen3"""

    name = "intent_classifier_gen1_gen2_gen3"
    target_module = "intent"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for intent_classifier_gen1_gen2_gen3: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "intent"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15001v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
