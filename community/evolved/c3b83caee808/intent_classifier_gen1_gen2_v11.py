"""Evolved strategy: Intent Classifier_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15001v1
Target module: intent
Generated: 2026-02-18T08:39:19.424515
Defines: IntentClassifier, create_intent_classifier
Code hash: cd52af7064276e97

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import re\nimport math\nfrom collections import defaultdict, Counter\n\nclass IntentClassifier:\n    def __init__(self):\n        self.intent_patterns = {\n            \'research\': {\n                \'keywords\': [\'search\', \'find\', \'look up\', \'investigate\', \'analyze\', \'study\', \'explore\', \'discover\', \'learn\', \'examine\', \'query\', \'retrieve\'],\n                \'patterns\': [r\'\\b(search|find|look\\s+up|investigate|analyze|study|explore|discover|research|query|retrieve)\\b\'],\n                \'context\': [\'papers\', \'information\', \'data\', \'knowledge\', \'facts\', \'articles\', \'sources\', \'database\', \'web\', \'literature\']\n            },\n            \'code\': {\n                \'keywords\': [\'write\', \'implement\', \'fix\', \'refactor\', \'build\', \'create\', \'develop\', \'code\', \'program\', \'debug\', \'compile\', \'deploy\'],\n                \'patterns\': [r\'\\b(write|implement|fix|refactor|build|create|develop|code|program|debug|compile|deploy)\\b\'],\n                \'context\': [\'function\', \'class\', \'method\', \'script\', \'application\', \'module\', \'bug\', \'feature\', \'api\', \'library\']\n            },\n            \'review\': {\n                \'keywords\': [\'review\', \'check\', \'audit\', \'inspect\', \'validate\', \'verify\', \'examine\', \'assess\', \'evaluate\', \'test\'],\n                \'patterns\': [r\'\\b(review|check|audit|inspect|validate|verify|examine|assess|evaluate|test)\\b\'],\n                \'context\': [\'logs\', \'code\', \'security\', \'quality\', \'compliance\', \'standards\', \'requirements\', \'documentation\']\n            },\n            \'monitor\': {\n                \'keywords\': [\'watch\', \'track\', \'alert\', \'detect\', \'observe\', \'monitor\', \'supervise\', \'guard\', \'scan\', \'measure\'],\n                \'patterns\': [r\'\\b(watch|track|alert|detect|observe|monitor|supervise|guard|scan|measure)\\b\'],\n                \'context\': [\'anomalies\', \'changes\', \'performance\', \'errors\', \'metrics\', \'status\', \'health\', \'system\', \'network\']\n            },\n            \'automate\': {\n                \'keywords\': [\'schedule\', \'trigger\', \'automate\', \'repeat\', \'cron\', \'batch\', \'routine\', \'workflow\', \'orchestrate\'],\n                \'patterns\': [r\'\\b(schedule|trigger|automate|repeat|cron|batch|routine|workflow|orchestrate)\\b\'],\n                \'context\': [\'task\', \'job\', \'process\', \'pipeline\', \'deployment\', \'backup\', \'maintenance\', \'integration\']\n            }\n        }\n        self.confidence_weights = {\n            \'keyword_match\': 0.4,\n            \'pattern_match\': 0.3,\n            \'context_match\': 0.2,\n            \'semantic_boost\': 0.1\n        }\n        self.learning_history = defaultdict(list)\n    \n    def preprocess_text(self, text):\n        """Clean and normalize input text"""\n        text = text.lower().strip()\n        text = re.sub(r\'[^\\w\\s]\', \' \', text)\n        text = re.sub(r\'\\s+\', \' \', text)\n        return text\n    \n    def calculate_intent_score(self, text, intent_data):\n        """Calculate confidence score for a specific intent"""\n        scores = {}\n        words = text.split()\n        \n        # Keyword matching with TF weighting\n        keyword_matches = sum(1 for word in words if word in intent_data[\'keywords\'])\n        scores[\'keyword_match\'] = min(keyword_matches / len(words), 1.0) if words else 0\n        \n        # Pattern matching\n        pattern_matches = sum(1 for pattern in intent_data[\'patterns\'] if re.search(pattern, text, re.IGNORECASE))\n        scores[\'pattern_match\'] = min(pattern_matches / len(intent_data[\'patterns\']), 1.0)\n        \n        # Context matching\n        context_matches = sum(1 for word in words if word in intent_data[\'context\'])\n        scores[\'context_match\'] = min(context_matches / len(words), 1.0) if words else 0\n        \n        # Semantic boost for co-occurrence\n        semantic_score = 0\n        if scores[\'keyword_match\'] > 0 and scores[\'context_match\'] > 0:\n            semantic_score = 0.5\n        scores[\'semantic_boost\'] = semantic_score\n        \n        # Weighted final score\n        final_score = sum(scores[key] * self.confidence_weights[key] for key in scores)\n        return final_score, scores\n    \n    def classify_intent(self, text, threshold=0.15):\n        """Classify intent with confidence scoring"""\n        if not text or not text.strip():\n            return {\'intent\': \'unknown\', \'confidence\': 0.0, \'alternatives\': []}\n        \n        processed_text = self.preprocess_text(text)\n        intent_scores = {}\n        detailed_scores = {}\n        \n        for intent, data in self.intent_patterns.items():\n            score, breakdown = self.calculate_intent_score(processed_text, data)\n            intent_scores[intent] = score\n            detailed_scores[intent] = breakdown\n        \n        # Sort by confidence\n        sorted_intents = sorted(intent_scores.items(), key=lambda x: x[1], reverse=True)\n        \n        if sorted_intents[0][1] < threshold:\n            return {\'intent\': \'unknown\', \'confidence\': 0.0, \'alternatives\': []}\n        \n        primary_intent = sorted_intents[0][0]\n        confidence = sorted_intents[0][1]\n        \n        # Get alternatives above threshold\n        alternatives = [(intent, score) for intent, score in sorted_intents[1:3] if score >= threshold * 0.7]\n        \n        result = {\n            \'intent\': primary_intent,\n            \'confidence\': confidence,\n            \'alternatives\': alternatives,\n            \'breakdown\': detailed_scores[primary_intent]\n        }\n        \n        # Store for learning\n        self.learning_history[primary_intent].append({\n            \'text\': text,\n            \'confidence\': confidence,\n            \'breakdown\': detailed_scores[primary_intent]\n        })\n        \n        return result\n    \n    def batch_classify(self, texts):\n        """Classify multiple texts efficiently"""\n        return [self.classify_intent(text) for text in texts]\n    \n    def get_intent_statistics(self):\n        """Get classification statistics for analysis"""\n        stats = {}\n        for intent, history in self.learning_history.items():\n            if history:\n                confidences = [h[\'confidence\'] for h in history]\n                stats[intent] = {\n                    \'count\': len(history),\n                    \'avg_confidence\': sum(confidences) / len(confidences),\n                    \'min_confidence\': min(confidences),\n                    \'max_confidence\': max(confidences)\n                }\n        return stats\n    \n    def suggest_improvements(self):\n        """Analyze patterns and suggest improvements"""\n        suggestions = []\n        stats = self.get_intent_statistics()\n        \n        for intent, data in stats.items():\n            if data[\'avg_confidence\'] < 0.3:\n                suggestions.append(f"Consider expanding keywords/patterns for \'{intent}\' intent (low avg confidence: {data[\'avg_confidence\']:.2f})")\n            if data[\'count\'] < 5:\n                suggestions.append(f"Need more training examples for \'{intent}\' intent (only {data[\'count\']} samples)")\n        \n        return suggestions\n\ndef create_intent_classifier():\n    """Factory function to create a configured intent classifier"""\n    return IntentClassifier()'

PATTERN_HASH = "cd52af7064276e97"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:intent_classifier_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class IntentClassifierGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Intent Classifier_gen1_gen2"""

    name = "intent_classifier_gen1_gen2"
    target_module = "intent"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for intent_classifier_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "intent"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15001v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
