"""Evolved strategy: Intent Classifier_gen1_gen2

Auto-generated by agos evolution engine.
Source paper: 2602.15829v1
Target module: intent
Generated: 2026-02-18T08:01:19.223848
Defines: IntentClassifier
Code hash: 5774acd616752934

Sandbox output: 
"""

from __future__ import annotations

import logging
from typing import Any

from agos.evolution.integrator import IntegrationStrategy, EvolutionProposal

_logger = logging.getLogger(__name__)

# ── Evolved pattern code ──────────────────────────────────────────
# This code passed sandbox validation and EXECUTES when apply() is called.

PATTERN_CODE = 'import re\nimport math\nfrom collections import defaultdict, Counter\n\nclass IntentClassifier:\n    def __init__(self):\n        self.intent_patterns = {\n            \'research\': {\n                \'keywords\': [\'search\', \'find\', \'look up\', \'investigate\', \'analyze\', \'study\', \'explore\', \'discover\', \'learn\', \'examine\', \'query\', \'retrieve\'],\n                \'patterns\': [r\'\\b(search|find|look\\s+up|investigate|analyze|study|explore|discover|research|query|retrieve)\\b\'],\n                \'context\': [\'papers\', \'information\', \'data\', \'knowledge\', \'facts\', \'details\', \'documentation\', \'sources\'],\n                \'weight\': 1.0\n            },\n            \'code\': {\n                \'keywords\': [\'write\', \'implement\', \'fix\', \'refactor\', \'build\', \'create\', \'develop\', \'code\', \'program\', \'debug\', \'compile\', \'deploy\'],\n                \'patterns\': [r\'\\b(write|implement|fix|refactor|build|create|develop|code|program|debug|compile|deploy)\\b\'],\n                \'context\': [\'function\', \'class\', \'script\', \'application\', \'module\', \'algorithm\', \'bug\', \'feature\', \'api\', \'library\'],\n                \'weight\': 1.2\n            },\n            \'review\': {\n                \'keywords\': [\'review\', \'check\', \'audit\', \'inspect\', \'validate\', \'verify\', \'examine\', \'assess\', \'evaluate\', \'test\'],\n                \'patterns\': [r\'\\b(review|check|audit|inspect|validate|verify|examine|assess|evaluate|test)\\b\'],\n                \'context\': [\'logs\', \'code\', \'security\', \'quality\', \'compliance\', \'performance\', \'results\', \'output\'],\n                \'weight\': 1.1\n            },\n            \'monitor\': {\n                \'keywords\': [\'watch\', \'track\', \'alert\', \'detect\', \'observe\', \'monitor\', \'supervise\', \'guard\', \'scan\', \'notify\'],\n                \'patterns\': [r\'\\b(watch|track|alert|detect|observe|monitor|supervise|guard|scan|notify)\\b\'],\n                \'context\': [\'anomalies\', \'changes\', \'events\', \'metrics\', \'status\', \'health\', \'errors\', \'performance\'],\n                \'weight\': 1.0\n            },\n            \'automate\': {\n                \'keywords\': [\'schedule\', \'trigger\', \'automate\', \'repeat\', \'cron\', \'batch\', \'routine\', \'periodic\', \'orchestrate\'],\n                \'patterns\': [r\'\\b(schedule|trigger|automate|repeat|cron|batch|routine|periodic|orchestrate)\\b\'],\n                \'context\': [\'task\', \'job\', \'process\', \'workflow\', \'pipeline\', \'deployment\', \'execution\'],\n                \'weight\': 1.3\n            }\n        }\n        self.confidence_threshold = 0.3\n        self.learning_buffer = defaultdict(list)\n    \n    def classify(self, text):\n        text_lower = text.lower()\n        scores = defaultdict(float)\n        \n        for intent, config in self.intent_patterns.items():\n            score = 0.0\n            \n            # Keyword matching with TF-IDF-like scoring\n            keyword_count = sum(1 for keyword in config[\'keywords\'] if keyword in text_lower)\n            if keyword_count > 0:\n                score += (keyword_count / len(config[\'keywords\'])) * 2.0\n            \n            # Pattern matching with regex\n            pattern_matches = sum(len(re.findall(pattern, text_lower)) for pattern in config[\'patterns\'])\n            if pattern_matches > 0:\n                score += min(pattern_matches * 1.5, 3.0)\n            \n            # Context relevance scoring\n            context_matches = sum(1 for context in config[\'context\'] if context in text_lower)\n            if context_matches > 0:\n                score += (context_matches / len(config[\'context\'])) * 1.0\n            \n            # Apply intent-specific weight\n            score *= config.get(\'weight\', 1.0)\n            \n            # Length normalization\n            score = score / math.log(len(text.split()) + 2)\n            \n            scores[intent] = score\n        \n        # Find best match\n        if not scores:\n            return \'unknown\', 0.0\n        \n        best_intent = max(scores, key=scores.get)\n        confidence = min(scores[best_intent], 1.0)\n        \n        # Multi-intent detection\n        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n        secondary_intents = [intent for intent, score in sorted_scores[1:] \n                           if score > self.confidence_threshold and score > sorted_scores[0][1] * 0.7]\n        \n        result = {\n            \'primary_intent\': best_intent,\n            \'confidence\': confidence,\n            \'secondary_intents\': secondary_intents,\n            \'all_scores\': dict(scores)\n        }\n        \n        return result\n    \n    def learn_from_feedback(self, text, correct_intent, feedback_score):\n        """Adaptive learning from user feedback"""\n        self.learning_buffer[correct_intent].append({\n            \'text\': text.lower(),\n            \'score\': feedback_score,\n            \'tokens\': text.lower().split()\n        })\n        \n        if len(self.learning_buffer[correct_intent]) >= 5:\n            self._update_patterns(correct_intent)\n    \n    def _update_patterns(self, intent):\n        """Update patterns based on learning buffer"""\n        samples = self.learning_buffer[intent]\n        token_freq = Counter()\n        \n        for sample in samples:\n            if sample[\'score\'] > 0.7:  # Only learn from high-confidence feedback\n                token_freq.update(sample[\'tokens\'])\n        \n        # Add frequent tokens as new keywords\n        for token, freq in token_freq.most_common(3):\n            if freq >= 2 and token not in self.intent_patterns[intent][\'keywords\']:\n                self.intent_patterns[intent][\'keywords\'].append(token)\n        \n        # Clear processed samples\n        self.learning_buffer[intent] = []\n    \n    def get_intent_suggestions(self, partial_text):\n        """Provide intent suggestions for partial input"""\n        if len(partial_text.strip()) < 3:\n            return []\n        \n        result = self.classify(partial_text)\n        suggestions = []\n        \n        if result[\'confidence\'] > 0.2:\n            suggestions.append(result[\'primary_intent\'])\n            suggestions.extend(result[\'secondary_intents\'])\n        \n        return suggestions[:3]\n    \n    def batch_classify(self, texts):\n        """Efficiently classify multiple texts"""\n        return [self.classify(text) for text in texts]'

PATTERN_HASH = "5774acd616752934"


def _execute_pattern() -> dict[str, Any]:
    """Execute the pattern code and return all defined names."""
    namespace = {"__builtins__": __builtins__}
    exec(compile(PATTERN_CODE, "<evolved:intent_classifier_gen1_gen2>", "exec"), namespace)
    return {k: v for k, v in namespace.items()
            if not k.startswith("_") and k != "__builtins__"}


# ── Strategy wrapper ──────────────────────────────────────────────


class IntentClassifierGen1Gen2Strategy(IntegrationStrategy):
    """Evolved strategy that EXECUTES: Intent Classifier_gen1_gen2"""

    name = "intent_classifier_gen1_gen2"
    target_module = "intent"

    def __init__(self, components: dict[str, Any] | None = None, **kwargs: Any) -> None:
        self._components = components or {}
        self._applied = False
        self._exports: dict[str, Any] = {}

    def validate(self, proposal: EvolutionProposal) -> tuple[bool, str]:
        return True, ""

    async def snapshot(self) -> dict[str, Any]:
        return {"applied": self._applied}

    async def apply(self, proposal: EvolutionProposal) -> list[str]:
        changes: list[str] = []

        # Execute the pattern code for real
        try:
            self._exports = _execute_pattern()
        except Exception as e:
            _logger.warning("Pattern execution failed for intent_classifier_gen1_gen2: %s", e)
            return [f"Pattern execution failed: {e}"]

        exported = [k for k in self._exports
                    if callable(self._exports[k]) or isinstance(self._exports[k], type)]
        if exported:
            changes.append(f"Executed pattern, defined: {', '.join(exported[:10])}")
        else:
            changes.append("Executed pattern (no callable exports)")

        # Hook into live system components
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        target = "intent"

        # Wire exported functions/classes into the target component
        if target.startswith("knowledge") and loom is not None:
            semantic = getattr(loom, "semantic", None)
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into semantic weave")
                    elif not hasattr(loom, f"_evolved_{fn_name}"):
                        setattr(loom, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into knowledge manager")
                elif isinstance(obj, type):
                    if semantic is not None and not hasattr(semantic, f"_evolved_{fn_name}"):
                        setattr(semantic, f"_evolved_{fn_name}", obj)
                        changes.append(f"Registered {fn_name} class in semantic weave")

        elif target.startswith("intent") and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) and not isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name}() into intent system")

        elif target == "policy" and audit_trail is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(audit_trail, f"_evolved_{fn_name}"):
                        setattr(audit_trail, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into policy system")

        elif target.startswith("orchestration") and event_bus is not None:
            for fn_name, obj in self._exports.items():
                if callable(obj) or isinstance(obj, type):
                    if not hasattr(event_bus, f"_evolved_{fn_name}"):
                        setattr(event_bus, f"_evolved_{fn_name}", obj)
                        changes.append(f"Hooked {fn_name} into orchestration")

        if not changes:
            changes.append("Pattern executed but no hookable exports found")

        self._applied = True
        changes.append("Source: 2602.15829v1")
        return changes

    async def rollback(self, snapshot_data: dict[str, Any]) -> None:
        loom = self._components.get("loom")
        event_bus = self._components.get("event_bus")
        audit_trail = self._components.get("audit_trail")
        for fn_name in self._exports:
            for comp in [loom, getattr(loom, "semantic", None) if loom else None,
                         event_bus, audit_trail]:
                if comp is not None:
                    attr = f"_evolved_{fn_name}"
                    if hasattr(comp, attr):
                        try:
                            delattr(comp, attr)
                        except Exception:
                            pass
        self._applied = snapshot_data.get("applied", False)

    async def health_check(self) -> bool:
        try:
            _execute_pattern()
            return True
        except Exception:
            return False
