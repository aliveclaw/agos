{
  "instance_id": "4d42b8932926",
  "agos_version": "0.1.0",
  "contributed_at": "2026-02-18T09:01:47.036429",
  "cycles_completed": 195,
  "strategies_applied": [
    {
      "name": "Long Context, Less Focus: A Scaling Gap in LLMs Revealed through ...",
      "module": "intent.personas",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15028v1",
          "title": "Long Context, Less Focus: A Scaling Gap in LLMs Revealed through Privacy and Personalization"
        }
      ],
      "sandbox_passed": false,
      "health_check_passed": true,
      "applied_at": "2026-02-17T21:27:54.139373",
      "applied_count": 1
    },
    {
      "name": "Cold-Start Personalization via Training-Free Priors from Structur...",
      "module": "knowledge.graph",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15012v1",
          "title": "Cold-Start Personalization via Training-Free Priors from Structured World Models"
        }
      ],
      "sandbox_passed": false,
      "health_check_passed": true,
      "applied_at": "2026-02-17T21:28:43.547706",
      "applied_count": 1
    },
    {
      "name": "Text Style Transfer with Parameter-efficient LLM Finetuning and R...",
      "module": "knowledge",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15013v1",
          "title": "Text Style Transfer with Parameter-efficient LLM Finetuning and Round-trip Translation"
        }
      ],
      "sandbox_passed": false,
      "health_check_passed": true,
      "applied_at": "2026-02-17T21:28:43.547722",
      "applied_count": 1
    },
    {
      "name": "Distributed Quantum Gaussian Processes for Multi-Agent Systems",
      "module": "knowledge.graph",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15006v1",
          "title": "Distributed Quantum Gaussian Processes for Multi-Agent Systems"
        }
      ],
      "sandbox_passed": false,
      "health_check_passed": true,
      "applied_at": "2026-02-17T21:29:34.335826",
      "applied_count": 1
    },
    {
      "name": "Operationalising the Superficial Alignment Hypothesis via Task Co...",
      "module": "intent",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15829v1",
          "title": "Operationalising the Superficial Alignment Hypothesis via Task Complexity"
        }
      ],
      "sandbox_passed": false,
      "health_check_passed": true,
      "applied_at": "2026-02-18T02:14:36.696676",
      "applied_count": 1
    },
    {
      "name": "This human study did not involve human subjects: Validating LLM s...",
      "module": "policy",
      "parameters": {},
      "source_papers": [
        {
          "arxiv_id": "2602.15785v1",
          "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence"
        }
      ],
      "sandbox_passed": true,
      "health_check_passed": true,
      "applied_at": "2026-02-18T02:15:48.013531",
      "applied_count": 1
    }
  ],
  "discovered_patterns": [
    {
      "name": "Token Budget Enforcer",
      "module": "policy",
      "code_snippet": "class TokenBudget:\n    def __init__(self, limit, burst_factor=1.5):\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n    def request(self, tokens):\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            return False\n        self.used += tokens\n        return True\n    def decay(self, factor=0.8):\n        self.used = int(self.used * factor)\n    @property\n    def utilization(self",
      "sandbox_output": "Budget: used=1150, violations=1, util=1.15\nPASS: Token budget enforcer validated\n",
      "source_paper": "2602.15004v1"
    },
    {
      "name": "Policy Rule Engine",
      "module": "policy",
      "code_snippet": "import re\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n    def matches(self, agent, action):\n        p = self.pattern.replace('*', '.*')\n        return bool(re.match(p, agent)) and (\n            self.action == '*' or self.action == action\n        )\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n    def add_rule(self, pattern, action, effect):\n        self.rules.ap",
      "sandbox_output": "Policy checks: 4/4 passed\nPASS: Policy rule engine validated\n",
      "source_paper": "2602.15815v1"
    }
  ],
  "meta_evolution": {
    "genomes": {
      "knowledge.semantic": {
        "component": "knowledge.semantic",
        "layer": "Semantic Work Substrate",
        "params": [
          {
            "name": "temperature",
            "current": null,
            "default": 0.0,
            "min_val": 0.0,
            "max_val": 1.0,
            "param_type": "float",
            "description": "Softmax retrieval diversity"
          },
          {
            "name": "track_access",
            "current": null,
            "default": false,
            "min_val": null,
            "max_val": null,
            "param_type": "bool",
            "description": "Access-based confidence tracking"
          },
          {
            "name": "relevance_threshold",
            "current": null,
            "default": 0.01,
            "min_val": 0.001,
            "max_val": 0.1,
            "param_type": "float",
            "description": "Minimum cosine similarity for results"
          },
          {
            "name": "confidence_decay_factor",
            "current": null,
            "default": 0.95,
            "min_val": 0.8,
            "max_val": 0.99,
            "param_type": "float",
            "description": "Confidence decay for unused knowledge"
          },
          {
            "name": "confidence_decay_days",
            "current": null,
            "default": 30,
            "min_val": 7,
            "max_val": 90,
            "param_type": "int",
            "description": "Days inactive before decay kicks in"
          }
        ],
        "fitness_score": 1.0,
        "last_evaluated": "2026-02-18T08:59:27.047219",
        "mutations_applied": 0
      },
      "knowledge.graph": {
        "component": "knowledge.graph",
        "layer": "Semantic Work Substrate",
        "params": [
          {
            "name": "default_traversal_depth",
            "current": 2,
            "default": 1,
            "min_val": 1,
            "max_val": 4,
            "param_type": "int",
            "description": "Default neighbor traversal hops"
          },
          {
            "name": "edge_weight_decay",
            "current": 0.9863,
            "default": 0.99,
            "min_val": 0.9,
            "max_val": 1.0,
            "param_type": "float",
            "description": "Weight decay per consolidation cycle"
          }
        ],
        "fitness_score": 0.943,
        "last_evaluated": "2026-02-18T08:59:27.047274",
        "mutations_applied": 2
      },
      "knowledge.consolidator": {
        "component": "knowledge.consolidator",
        "layer": "Semantic Work Substrate",
        "params": [
          {
            "name": "older_than_hours",
            "current": 48,
            "default": 24,
            "min_val": 6,
            "max_val": 168,
            "param_type": "int",
            "description": "Consolidate events older than N hours"
          },
          {
            "name": "min_cluster_size",
            "current": 4,
            "default": 3,
            "min_val": 2,
            "max_val": 10,
            "param_type": "int",
            "description": "Minimum events to form a summary"
          },
          {
            "name": "max_concurrent_writes",
            "current": 6,
            "default": 5,
            "min_val": 1,
            "max_val": 20,
            "param_type": "int",
            "description": "Semaphore limit for batch ops"
          }
        ],
        "fitness_score": 0.5,
        "last_evaluated": "2026-02-18T08:59:27.047309",
        "mutations_applied": 50
      },
      "knowledge.loom": {
        "component": "knowledge.loom",
        "layer": "Semantic Work Substrate",
        "params": [
          {
            "name": "use_layered_recall",
            "current": true,
            "default": false,
            "min_val": null,
            "max_val": null,
            "param_type": "bool",
            "description": "Priority-ordered layer retrieval"
          },
          {
            "name": "recall_limit",
            "current": 20,
            "default": 10,
            "min_val": 3,
            "max_val": 50,
            "param_type": "int",
            "description": "Default recall result limit"
          }
        ],
        "fitness_score": 0.5,
        "last_evaluated": "2026-02-18T08:59:27.047342",
        "mutations_applied": 15
      },
      "intent.engine": {
        "component": "intent.engine",
        "layer": "Agent & Intent Intelligence",
        "params": [
          {
            "name": "default_strategy",
            "current": null,
            "default": "solo",
            "min_val": null,
            "max_val": null,
            "param_type": "str",
            "description": "Fallback coordination strategy"
          },
          {
            "name": "max_intent_tokens",
            "current": 261,
            "default": 500,
            "min_val": 200,
            "max_val": 1500,
            "param_type": "int",
            "description": "Token limit for intent classification"
          }
        ],
        "fitness_score": 0.75,
        "last_evaluated": "2026-02-18T08:59:27.047374",
        "mutations_applied": 1
      },
      "intent.personas": {
        "component": "intent.personas",
        "layer": "Agent & Intent Intelligence",
        "params": [
          {
            "name": "researcher_budget",
            "current": 450000,
            "default": 200000,
            "min_val": 50000,
            "max_val": 500000,
            "param_type": "int",
            "description": "Researcher agent token budget"
          },
          {
            "name": "coder_budget",
            "current": 425000,
            "default": 200000,
            "min_val": 50000,
            "max_val": 500000,
            "param_type": "int",
            "description": "Coder agent token budget"
          },
          {
            "name": "orchestrator_budget",
            "current": 400000,
            "default": 200000,
            "min_val": 50000,
            "max_val": 500000,
            "param_type": "int",
            "description": "Orchestrator agent token budget"
          },
          {
            "name": "researcher_max_turns",
            "current": 45,
            "default": 30,
            "min_val": 5,
            "max_val": 80,
            "param_type": "int",
            "description": "Researcher max turns"
          },
          {
            "name": "coder_max_turns",
            "current": 55,
            "default": 40,
            "min_val": 10,
            "max_val": 100,
            "param_type": "int",
            "description": "Coder max turns"
          },
          {
            "name": "orchestrator_max_turns",
            "current": 33,
            "default": 50,
            "min_val": 10,
            "max_val": 100,
            "param_type": "int",
            "description": "Orchestrator max turns"
          }
        ],
        "fitness_score": 0.5,
        "last_evaluated": "2026-02-18T08:59:27.047406",
        "mutations_applied": 73
      },
      "orchestration.planner": {
        "component": "orchestration.planner",
        "layer": "Agent Orchestration & Workflow",
        "params": [
          {
            "name": "parallel_threshold",
            "current": null,
            "default": 3,
            "min_val": 2,
            "max_val": 10,
            "param_type": "int",
            "description": "Min subtasks to trigger parallel execution"
          },
          {
            "name": "pipeline_max_agents",
            "current": 4,
            "default": 5,
            "min_val": 2,
            "max_val": 10,
            "param_type": "int",
            "description": "Max agents in a pipeline"
          }
        ],
        "fitness_score": 0.75,
        "last_evaluated": "2026-02-18T08:59:27.047438",
        "mutations_applied": 1
      },
      "orchestration.runtime": {
        "component": "orchestration.runtime",
        "layer": "Agent Orchestration & Workflow",
        "params": [
          {
            "name": "max_concurrent_agents",
            "current": 47,
            "default": 50,
            "min_val": 5,
            "max_val": 200,
            "param_type": "int",
            "description": "Max agents running simultaneously"
          }
        ],
        "fitness_score": 0.5,
        "last_evaluated": "2026-02-18T08:59:27.047470",
        "mutations_applied": 1
      },
      "policy.engine": {
        "component": "policy.engine",
        "layer": "Identity & Governance",
        "params": [
          {
            "name": "default_max_tokens",
            "current": null,
            "default": 200000,
            "min_val": 50000,
            "max_val": 1000000,
            "param_type": "int",
            "description": "Default agent token budget"
          },
          {
            "name": "default_max_turns",
            "current": null,
            "default": 50,
            "min_val": 10,
            "max_val": 200,
            "param_type": "int",
            "description": "Default agent turn limit"
          },
          {
            "name": "default_rate_limit",
            "current": null,
            "default": 60,
            "min_val": 10,
            "max_val": 200,
            "param_type": "int",
            "description": "Tool calls per minute"
          },
          {
            "name": "default_read_only",
            "current": null,
            "default": false,
            "min_val": null,
            "max_val": null,
            "param_type": "bool",
            "description": "Default read-only mode"
          }
        ],
        "fitness_score": 1.0,
        "last_evaluated": "2026-02-18T08:59:27.047515",
        "mutations_applied": 0
      },
      "events.bus": {
        "component": "events.bus",
        "layer": "Episodic Experience",
        "params": [
          {
            "name": "history_limit",
            "current": null,
            "default": 500,
            "min_val": 100,
            "max_val": 5000,
            "param_type": "int",
            "description": "Max events in memory"
          }
        ],
        "fitness_score": 1.0,
        "last_evaluated": "2026-02-18T08:59:27.047612",
        "mutations_applied": 0
      },
      "events.tracing": {
        "component": "events.tracing",
        "layer": "Episodic Experience",
        "params": [
          {
            "name": "max_traces",
            "current": 260,
            "default": 200,
            "min_val": 50,
            "max_val": 1000,
            "param_type": "int",
            "description": "Max traces retained"
          }
        ],
        "fitness_score": 0.5,
        "last_evaluated": "2026-02-18T08:59:27.047658",
        "mutations_applied": 1
      }
    },
    "recent_mutations": [
      {
        "id": "7bbdf296154c",
        "component": "intent.personas",
        "param_name": "orchestrator_budget",
        "old_value": 350000,
        "new_value": 200000,
        "reason": "LLM: Reduce orchestrator budget to better balance with researcher (122210) and coder (150000) budgets - current 350000 creates resource imbalance that may contribute to coordination issues",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:31:16.470717"
      },
      {
        "id": "b3234862fc9e",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 72,
        "new_value": 48,
        "reason": "LLM: Reduce consolidation threshold from 72 to 48 hours to process knowledge more frequently, which should help reduce policy violations by keeping compliance knowledge more current",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:31:16.470731"
      },
      {
        "id": "aa5175471677",
        "component": "intent.personas",
        "param_name": "orchestrator_budget",
        "old_value": 200000,
        "new_value": 243856,
        "reason": "Fitness 0.50 < 0.6, adjusting orchestrator_budget",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:32:32.679400"
      },
      {
        "id": "8741df92a398",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 48,
        "new_value": 24,
        "reason": "LLM: Reduce consolidation threshold from 48 to 24 hours to process knowledge faster, which may help reduce policy violations by ensuring more current information is available for decision-making",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:42:05.563425"
      },
      {
        "id": "a79588ac2af5",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 35,
        "new_value": 50,
        "reason": "LLM: Increase researcher turns from 35 to 50 to allow more thorough investigation and validation, potentially reducing policy violations through better research",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:42:05.563639"
      },
      {
        "id": "9fdd25cfabd1",
        "component": "knowledge.loom",
        "param_name": "recall_limit",
        "old_value": 25,
        "new_value": 40,
        "reason": "LLM: Increase recall limit from 25 to 40 to provide more context for decision-making, leveraging the perfect retrieval hit rate to help reduce policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:42:05.563727"
      },
      {
        "id": "3615004e1421",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 24,
        "new_value": 28,
        "reason": "Fitness 0.50 < 0.6, adjusting older_than_hours",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:42:57.070803"
      },
      {
        "id": "a237a7d6b7c6",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 28,
        "new_value": 12,
        "reason": "LLM: Reduce from 28 to 12 hours to consolidate knowledge more frequently, which should help reduce policy violations by keeping knowledge more current and organized",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:48:19.496299"
      },
      {
        "id": "eb77bd185098",
        "component": "knowledge.loom",
        "param_name": "recall_limit",
        "old_value": 40,
        "new_value": 25,
        "reason": "LLM: Reduce from 40 to 25 to limit recall scope and potentially reduce the aggressive behavior causing policy violations while maintaining good retrieval performance",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:48:19.496386"
      },
      {
        "id": "34f22984b92d",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 50,
        "new_value": 35,
        "reason": "LLM: Reduce researcher turns from 50 to 35 to constrain exploration and reduce policy violations while keeping within effective research bounds",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:48:19.496678"
      },
      {
        "id": "dcfc3b15bc1f",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 12,
        "new_value": 6,
        "reason": "LLM: With perfect retrieval rates but high policy violations, consolidating knowledge more frequently (every 6 hours instead of 12) should improve data freshness and reduce conflicts that may be causing policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:53:23.049230"
      },
      {
        "id": "79c5b9edb5ee",
        "component": "knowledge.loom",
        "param_name": "recall_limit",
        "old_value": 25,
        "new_value": 15,
        "reason": "LLM: Reducing recall limit from 25 to 15 should help focus on most relevant knowledge and potentially reduce the cognitive load that may be contributing to policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:53:23.049389"
      },
      {
        "id": "ef375263425b",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 35,
        "new_value": 20,
        "reason": "LLM: Reducing researcher max turns from 35 to 20 should constrain overly aggressive research behavior that may be contributing to the 100% policy violation rate while maintaining effectiveness",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T07:53:23.049474"
      },
      {
        "id": "31428a927648",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 6,
        "new_value": 24,
        "reason": "LLM: Increase consolidation threshold to reduce aggressive knowledge merging that may be causing policy violations by creating inconsistent state",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:05:19.925711"
      },
      {
        "id": "894720a0e5ef",
        "component": "knowledge.loom",
        "param_name": "recall_limit",
        "old_value": 15,
        "new_value": 8,
        "reason": "LLM: Reduce recall limit to prevent information overload that could lead to poor decision-making and policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:05:19.925839"
      },
      {
        "id": "59473838a0c3",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 20,
        "new_value": 12,
        "reason": "LLM: Reduce researcher turn limit to prevent excessive exploration that may be contributing to policy violations through unconstrained behavior",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:05:19.925910"
      },
      {
        "id": "b0abaf3457c9",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 24,
        "new_value": 14,
        "reason": "Fitness 0.50 < 0.6, adjusting older_than_hours",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:07:34.956277"
      },
      {
        "id": "18a4020de071",
        "component": "intent.personas",
        "param_name": "researcher_budget",
        "old_value": 122210,
        "new_value": 350000,
        "reason": "LLM: Current budget of 122210 is too low, forcing rushed research that likely contributes to policy violations. Increasing to 350000 provides adequate resources for thorough, compliant work.",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:10:24.249981"
      },
      {
        "id": "415cb52af4a5",
        "component": "intent.personas",
        "param_name": "coder_budget",
        "old_value": 150000,
        "new_value": 300000,
        "reason": "LLM: Budget of 150000 appears insufficient for proper code development with policy compliance. Doubling to 300000 allows for better quality assurance and adherence to coding standards.",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:10:24.250022"
      },
      {
        "id": "d9dfaa3dca6f",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 12,
        "new_value": 25,
        "reason": "LLM: Only 12 turns may be forcing researchers to skip validation steps that ensure policy compliance. Increasing to 25 allows for more thorough research processes.",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:10:24.250048"
      },
      {
        "id": "0a10711a6d74",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 14,
        "new_value": 48,
        "reason": "LLM: Increase consolidation threshold from 14 to 48 hours to reduce frequent consolidation that may be contributing to policy violations by disrupting active knowledge workflows",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:15:33.188872"
      },
      {
        "id": "e58055f200b8",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 25,
        "new_value": 45,
        "reason": "LLM: Increase researcher turns from 25 to 45 to allow more thorough exploration and reduce rushed decisions that could trigger policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:15:33.188910"
      },
      {
        "id": "539db48bd075",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 12,
        "new_value": 35,
        "reason": "LLM: Increase coder turns from 12 to 35 to provide sufficient iteration capacity for proper code development and testing, reducing policy violations from incomplete implementations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:15:33.188947"
      },
      {
        "id": "fa4003bdc292",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 48,
        "new_value": 24,
        "reason": "LLM: Reduce consolidation threshold to process knowledge more frequently, potentially reducing policy violations by keeping information more current and accessible",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:20:40.723250"
      },
      {
        "id": "4af152889083",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 45,
        "new_value": 25,
        "reason": "LLM: Limit researcher exploration to reduce policy violations while maintaining effectiveness - shorter interaction cycles may improve compliance",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:20:40.723286"
      },
      {
        "id": "83457a191b75",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 35,
        "new_value": 20,
        "reason": "LLM: Constrain coder iterations to prevent runaway processes that may be contributing to policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:20:40.723307"
      },
      {
        "id": "6b310b2a5db1",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 24,
        "new_value": 27,
        "reason": "Fitness 0.50 < 0.6, adjusting older_than_hours",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:27:00.404822"
      },
      {
        "id": "c54239bdafa1",
        "component": "intent.personas",
        "param_name": "orchestrator_budget",
        "old_value": 243856,
        "new_value": 400000,
        "reason": "LLM: Policy violation rate is 100% - the orchestrator needs significantly more budget to properly coordinate and enforce policies across researcher/coder activities",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:29:44.146398"
      },
      {
        "id": "9e48c80e5cf3",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 27,
        "new_value": 72,
        "reason": "LLM: With perfect retrieval hit rates and high graph density, knowledge consolidation can be less frequent to reduce system overhead and allow more time for knowledge to mature",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:29:44.146487"
      },
      {
        "id": "41bd8799b04a",
        "component": "knowledge.loom",
        "param_name": "recall_limit",
        "old_value": 8,
        "new_value": 20,
        "reason": "LLM: High activity levels and topic diversity suggest the system needs broader context recall to better inform decision-making and reduce policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:29:44.146530"
      },
      {
        "id": "9de040c3d80f",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 72,
        "new_value": 48,
        "reason": "LLM: Reduce from 72 to 48 hours to consolidate knowledge more frequently, which should help reduce policy violations by keeping knowledge more current and organized",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:34:06.160388"
      },
      {
        "id": "b78d3344c357",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 25,
        "new_value": 15,
        "reason": "LLM: Reduce from 25 to 15 turns to limit researcher exploration depth, preventing excessive resource usage that may be causing policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:34:06.160451"
      },
      {
        "id": "77502d58bafe",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 20,
        "new_value": 15,
        "reason": "LLM: Reduce from 20 to 15 turns to constrain coder execution cycles, helping to reduce the 100% policy violation rate by limiting potentially risky operations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:34:06.160522"
      },
      {
        "id": "9ee664735a53",
        "component": "intent.personas",
        "param_name": "researcher_budget",
        "old_value": 350000,
        "new_value": 450000,
        "reason": "LLM: Increase budget to reduce policy violations - current 350k may be insufficient given 100% violation rate",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:39:00.840325"
      },
      {
        "id": "d33e001b91b5",
        "component": "intent.personas",
        "param_name": "coder_budget",
        "old_value": 300000,
        "new_value": 425000,
        "reason": "LLM: Boost coder budget significantly to handle complex tasks without hitting resource limits that trigger policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:39:00.840400"
      },
      {
        "id": "1907d3275936",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 15,
        "new_value": 35,
        "reason": "LLM: Allow more turns for thorough research given perfect retrieval hit rate - current 15 turns may be too restrictive",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:39:00.840450"
      },
      {
        "id": "dceb155d0c6a",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 15,
        "new_value": 45,
        "reason": "LLM: With high budgets (425k) but only 15 max turns, coders may be hitting turn limits before completing complex tasks, potentially causing policy violations as they rush or take shortcuts",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:43:07.614116"
      },
      {
        "id": "7e5b0e120e01",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 48,
        "new_value": 24,
        "reason": "LLM: Reducing consolidation threshold from 48 to 24 hours will create more frequent knowledge updates, helping agents access fresher consolidated insights for better decision-making",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:43:07.614156"
      },
      {
        "id": "96343f198f71",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 35,
        "new_value": 50,
        "reason": "LLM: Increasing researcher turns from 35 to 50 allows more thorough investigation and planning, which should reduce downstream policy violations by other agents",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:43:07.614180"
      },
      {
        "id": "6460da8d59ab",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 24,
        "new_value": 46,
        "reason": "Fitness 0.50 < 0.6, adjusting older_than_hours",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:45:46.886295"
      },
      {
        "id": "a77fbd1c91ee",
        "component": "knowledge.consolidator",
        "param_name": "max_concurrent_writes",
        "old_value": 12,
        "new_value": 6,
        "reason": "LLM: Reducing concurrent writes from 12 to 6 should help prevent policy violations that may be caused by excessive simultaneous knowledge operations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:48:26.657057"
      },
      {
        "id": "998b396f54c6",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 50,
        "new_value": 25,
        "reason": "LLM: Halving researcher max turns from 50 to 25 to reduce resource contention and potential policy violations from overly long research sessions",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:48:26.657188"
      },
      {
        "id": "2355289d7f54",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 45,
        "new_value": 25,
        "reason": "LLM: Reducing coder max turns from 45 to 25 to limit extended coding sessions that may be contributing to the high policy violation rate",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:48:26.657251"
      },
      {
        "id": "15e25cd4ad2c",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 25,
        "new_value": 60,
        "reason": "LLM: Increase from 25 to 60 to allow researchers more iterations to complete tasks properly, potentially reducing policy violations caused by rushed or incomplete work",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:53:23.535354"
      },
      {
        "id": "1578a7ac59c6",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 25,
        "new_value": 70,
        "reason": "LLM: Increase from 25 to 70 to give coders sufficient turns to implement solutions correctly, reducing policy violations from incomplete or hasty code",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:53:23.535461"
      },
      {
        "id": "a004d2991f28",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 46,
        "new_value": 24,
        "reason": "LLM: Reduce from 46 to 24 hours to consolidate knowledge more frequently, ensuring agents have access to recent consolidated insights that may help them follow policies better",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:53:23.535528"
      },
      {
        "id": "cd9eeead09e6",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 24,
        "new_value": 32,
        "reason": "Fitness 0.50 < 0.6, adjusting older_than_hours",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:56:54.724481"
      },
      {
        "id": "e247c7d42dcc",
        "component": "knowledge.consolidator",
        "param_name": "older_than_hours",
        "old_value": 32,
        "new_value": 48,
        "reason": "LLM: Increase consolidation threshold to reduce memory pressure and potential policy violations from excessive knowledge fragmentation",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:59:32.461344"
      },
      {
        "id": "a28fdb8dabfa",
        "component": "intent.personas",
        "param_name": "researcher_max_turns",
        "old_value": 60,
        "new_value": 45,
        "reason": "LLM: Reduce researcher turn limit to prevent runaway processes that may be contributing to policy violations",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:59:32.461449"
      },
      {
        "id": "a5de8c4fdeb6",
        "component": "intent.personas",
        "param_name": "coder_max_turns",
        "old_value": 70,
        "new_value": 55,
        "reason": "LLM: Reduce coder turn limit to maintain tighter control over execution cycles and reduce policy violation opportunities",
        "fitness_before": 0.5,
        "fitness_after": null,
        "applied": true,
        "timestamp": "2026-02-18T08:59:32.461506"
      }
    ],
    "timestamp": "2026-02-18T08:59:33.808802"
  },
  "meta_cycles_completed": 144,
  "design_archive": {
    "max_size": 50,
    "temperature": 0.3,
    "entries": [
      {
        "id": "b49abe134c43",
        "strategy_name": "Token Budget Enforcer",
        "module": "policy",
        "code_hash": "abc0dfd9b67254ea",
        "code_snippet": "class TokenBudget:\n    def __init__(self, limit, burst_factor=1.5):\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n    def request(self, tokens):\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            return False\n        self.used += tokens\n        return True\n    def decay(self, factor=0.8):\n        self.used = int(self.used * factor)\n    @property\n    def utilization(self):\n        return round(self.used / self.limit, 3) if self.limit else 0\n\nb = TokenBudget(limit=1000, burst_factor=1.5)\nassert b.request(500)\nassert b.request(400)\nassert b.utilization == 0.9\nassert not b.request(700)\nassert b.violations == 1\nb.decay(0.5)\nassert b.request(700)\nprint(f'Budget: used={b.used}, violations={b.violations}, util={b.utilization}')\nprint('PASS: Token budget enforcer validated')\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 0,
        "parent_id": "",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-17T21:29:34.338595"
      },
      {
        "id": "f0480d8f9906",
        "strategy_name": "Policy Rule Engine",
        "module": "policy",
        "code_hash": "12a3a1a18f00ea79",
        "code_snippet": "import re\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n    def matches(self, agent, action):\n        p = self.pattern.replace('*', '.*')\n        return bool(re.match(p, agent)) and (\n            self.action == '*' or self.action == action\n        )\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n    def add_rule(self, pattern, action, effect):\n        self.rules.append(PolicyRule(pattern, action, effect))\n    def check(self, agent, action):\n        for rule in self.rules:\n            if rule.matches(agent, action):\n                return rule.effect\n        return 'deny'\n\npe = PolicyEngine()\npe.add_rule('admin*', '*', 'allow')\npe.add_rule('agent_*', 'read', 'allow')\npe.add_rule('agent_*', 'write', 'deny')\npe.add_rule('*', '*', 'deny')\nassert pe.check('admin_root', 'delete') == 'allow'\nassert pe.check('agent_scanner', 'read') == 'allow'\nassert pe.check('agent_scanner', 'write') == 'deny'\nassert pe.check('unknown', 'read') == 'deny'\nprint('Policy checks: 4/4 passed')\nprint('PASS: Policy rule engine validated')\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 0,
        "parent_id": "",
        "source_paper": "2602.15815v1",
        "created_at": "2026-02-18T02:13:20.790547"
      },
      {
        "id": "b4e80c865dfe",
        "strategy_name": "Token Budget Enforcer",
        "module": "policy",
        "code_hash": "abc0dfd9b67254ea",
        "code_snippet": "class TokenBudget:\n    def __init__(self, limit, burst_factor=1.5):\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n    def request(self, tokens):\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            return False\n        self.used += tokens\n        return True\n    def decay(self, factor=0.8):\n        self.used = int(self.used * factor)\n    @property\n    def utilization(self):\n        return round(self.used / self.limit, 3) if self.limit else 0\n\nb = TokenBudget(limit=1000, burst_factor=1.5)\nassert b.request(500)\nassert b.request(400)\nassert b.utilization == 0.9\nassert not b.request(700)\nassert b.violations == 1\nb.decay(0.5)\nassert b.request(700)\nprint(f'Budget: used={b.used}, violations={b.violations}, util={b.utilization}')\nprint('PASS: Token budget enforcer validated')\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 0,
        "parent_id": "",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T02:14:36.699189"
      },
      {
        "id": "3fc1402ad9eb",
        "strategy_name": "Policy Rule Engine",
        "module": "policy",
        "code_hash": "12a3a1a18f00ea79",
        "code_snippet": "import re\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n    def matches(self, agent, action):\n        p = self.pattern.replace('*', '.*')\n        return bool(re.match(p, agent)) and (\n            self.action == '*' or self.action == action\n        )\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n    def add_rule(self, pattern, action, effect):\n        self.rules.append(PolicyRule(pattern, action, effect))\n    def check(self, agent, action):\n        for rule in self.rules:\n            if rule.matches(agent, action):\n                return rule.effect\n        return 'deny'\n\npe = PolicyEngine()\npe.add_rule('admin*', '*', 'allow')\npe.add_rule('agent_*', 'read', 'allow')\npe.add_rule('agent_*', 'write', 'deny')\npe.add_rule('*', '*', 'deny')\nassert pe.check('admin_root', 'delete') == 'allow'\nassert pe.check('agent_scanner', 'read') == 'allow'\nassert pe.check('agent_scanner', 'write') == 'deny'\nassert pe.check('unknown', 'read') == 'deny'\nprint('Policy checks: 4/4 passed')\nprint('PASS: Policy rule engine validated')\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 0,
        "parent_id": "",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T02:15:48.016326"
      },
      {
        "id": "60b0d387cade",
        "strategy_name": "Policy Rule Engine",
        "module": "policy",
        "code_hash": "12a3a1a18f00ea79",
        "code_snippet": "import re\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n    def matches(self, agent, action):\n        p = self.pattern.replace('*', '.*')\n        return bool(re.match(p, agent)) and (\n            self.action == '*' or self.action == action\n        )\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n    def add_rule(self, pattern, action, effect):\n        self.rules.append(PolicyRule(pattern, action, effect))\n    def check(self, agent, action):\n        for rule in self.rules:\n            if rule.matches(agent, action):\n                return rule.effect\n        return 'deny'\n\npe = PolicyEngine()\npe.add_rule('admin*', '*', 'allow')\npe.add_rule('agent_*', 'read', 'allow')\npe.add_rule('agent_*', 'write', 'deny')\npe.add_rule('*', '*', 'deny')\nassert pe.check('admin_root', 'delete') == 'allow'\nassert pe.check('agent_scanner', 'read') == 'allow'\nassert pe.check('agent_scanner', 'write') == 'deny'\nassert pe.check('unknown', 'read') == 'deny'\nprint('Policy checks: 4/4 passed')\nprint('PASS: Policy rule engine validated')\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 0,
        "parent_id": "",
        "source_paper": "2602.15785v1",
        "created_at": "2026-02-18T02:15:48.016807"
      },
      {
        "id": "04bacb44c667",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "f8542feaa4788700",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom typing import Dict, List, Optional, Any\n\nclass PolicyRule:\n    def __init__(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n        self.priority = priority\n        self.conditions = conditions or {}\n        self._compiled_pattern = re.compile(pattern.replace('*', '.*'))\n    \n    def matches(self, agent: str, action: str, context: Dict = None) -> bool:\n        context = context or {}\n        \n        # Check pattern and action match\n        if not self._compiled_pattern.match(agent):\n            return False\n        if self.action != '*' and self.action != action:\n            return False\n            \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n                \n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules: List[PolicyRule] = []\n        self.cache: Dict[str, str] = {}\n        self.stats = defaultdict(int)\n    \n    def add_rule(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions)\n        self.rules.append(rule)\n        self._sort_rules()\n        self.cache.clear()\n    \n    def _sort_rules(self):\n        \"\"\"Sort rules by priority (higher first), then by specificity\"\"\"\n        self.rules.sort(key=lambda r: (-r.priority, -len(r.pattern.replace('*', ''))))\n    \n    def check(self, agent: str, action: str, context: Dict = None) -> str:\n        cache_key = f\"{agent}:{action}:{json.dumps(context or {}, sort_keys=True)}\"\n        \n        if cache_key in self.cache:\n            self.stats['cache_hits'] += 1\n            return self.cache[cache_key]\n        \n        self.stats['evaluations'] += 1\n        \n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n                result = rule.effect\n                self.cache[cache_key] = result\n                self.stats[f'effect_{result}'] += 1\n                return result\n        \n        # Default deny\n        self.cache[cache_key] = 'deny'\n        self.stats['effect_deny'] += 1\n        return 'deny'\n    \n    def bulk_check(self, requests: List[tuple]) -> List[str]:\n        \"\"\"Efficiently process multiple policy checks\"\"\"\n        return [self.check(*req) for req in requests]\n    \n    def get_applicable_rules(self, agent: str, action: str, context: Dict = None) -> List[PolicyRule]:\n        \"\"\"Return all rules that would match the given request\"\"\"\n        return [rule for rule in self.rules if rule.matches(agent, action, context)]\n    \n    def export_policy(self) -> Dict:\n        \"\"\"Export policy configuration\"\"\"\n        return {\n            'rules': [\n                {\n                    'pattern': rule",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "3fc1402ad9eb",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T07:24:15.941481"
      },
      {
        "id": "cf00bbea3162",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "e0f248c523b5c092",
        "code_snippet": "import time\nimport math\nfrom collections import deque\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=1.5, window_size=10):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 1.0\n        self.adaptation_factor = 0.1\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Record request pattern\n        self.request_history.append({\n            'tokens': tokens,\n            'timestamp': time.time(),\n            'granted': False\n        })\n        \n        # Check against burst limit\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            self._adapt_on_violation()\n            return False\n            \n        self.used += tokens\n        self.request_history[-1]['granted'] = True\n        self._adapt_on_success()\n        return True\n    \n    def _auto_decay(self):\n        now = time.time()\n        if now - self.last_decay >= self.auto_decay_interval:\n            elapsed_intervals = (now - self.last_decay) / self.auto_decay_interval\n            decay_factor = 0.8 ** elapsed_intervals\n            self.decay(decay_factor)\n            self.last_decay = now\n    \n    def decay(self, factor=0.8):\n        self.used = max(0, int(self.used * factor))\n    \n    def _adapt_on_violation(self):\n        # Tighten limits when violations occur\n        violation_rate = self.violations / max(1, len(self.request_history))\n        if violation_rate > 0.2:  # More than 20% violations\n            self.limit = max(self.base_limit * 0.5, \n                           self.limit * (1 - self.adaptation_factor))\n            self.burst_limit = int(self.limit * 1.5)\n    \n    def _adapt_on_success(self):\n        # Gradually increase limits when requests succeed\n        if len(self.request_history) >= self.window_size:\n            recent_violations = sum(1 for req in self.request_history \n                                  if not req['granted'])\n            if recent_violations == 0:  # No recent violations\n                self.limit = min(self.base_limit * 2, \n                               self.limit * (1 + self.adaptation_factor * 0.1))\n                self.burst_limit = int(self.limit * 1.5)\n    \n    @property\n    def utilization(self):\n        return round(self.used / self.limit, 3) if self.limit else 0\n    \n    @property\n    def efficiency(self):\n        if not self.request_history:\n            return 1.0\n        granted = sum(1 for req in self.request_history if req['granted'])\n        return round(granted / len(self.request_history), 3)\n    \n    def get_stats(self):\n        return {\n            'used': self.used,\n            'limit': self.limit,\n            'violations': self.violations,\n            'utilization'",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b4e80c865dfe",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T07:24:37.979750"
      },
      {
        "id": "68c5c1ec82a3",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "396ba78bc1ec3540",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom enum import Enum\n\nclass Effect(Enum):\n    ALLOW = \"allow\"\n    DENY = \"deny\"\n    AUDIT = \"audit\"\n\nclass Priority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        self.pattern = re.compile(pattern.replace('*', '.*').replace('?', '.'))\n        self.action_pattern = re.compile(action.replace('*', '.*').replace('?', '.')) if action != '*' else None\n        self.effect = Effect(effect) if isinstance(effect, str) else effect\n        self.priority = priority if isinstance(priority, Priority) else Priority(priority)\n        self.conditions = conditions or {}\n        self.metadata = metadata or {}\n        self.hit_count = 0\n    \n    def matches(self, agent, action, context=None):\n        context = context or {}\n        \n        # Check agent pattern\n        if not self.pattern.match(agent):\n            return False\n        \n        # Check action pattern\n        if self.action_pattern and not self.action_pattern.match(action):\n            return False\n        \n        # Check conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n        \n        self.hit_count += 1\n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n        self.rule_index = defaultdict(list)  # Index by agent pattern for faster lookup\n        self.audit_log = []\n        self.cache = {}\n        self.cache_hits = 0\n        self.cache_misses = 0\n    \n    def add_rule(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions, metadata)\n        self.rules.append(rule)\n        # Sort rules by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority.value, reverse=True)\n        self._clear_cache()\n        return rule\n    \n    def remove_rule(self, rule):\n        if rule in self.rules:\n            self.rules.remove(rule)\n            self._clear_cache()\n    \n    def check(self, agent, action, context=None):\n        cache_key = (agent, action, json.dumps(context or {}, sort_keys=True))\n        \n        # Check cache first\n        if cache_key in self.cache:\n            self.cache_hits += 1\n            result = self.cache[cache_key]\n            if result['effect'] == Effect.AUDIT:\n                self._log_audit(agent, action, result, context)\n            return result['effect'].value\n        \n        self.cache_misses += 1\n        \n        # Find matching rule with highest priority\n        matching_rule = None\n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n                matching_rule = rule\n                break\n        \n        # Default to deny if no rule matches\n        effect = matching_rule",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "3fc1402ad9eb",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T07:28:17.264847"
      },
      {
        "id": "ec3f2a8ac443",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "cda9cf662445be98",
        "code_snippet": "def solution(s):\n    n = len(s)\n    if n == 0:\n        return 0\n    \n    # dp[i] represents the number of ways to decode s[0:i]\n    dp = [0] * (n + 1)\n    dp[0] = 1  # Empty string has one way to decode\n    \n    # Check if the first character can be decoded\n    dp[1] = 1 if s[0] != '0' else 0\n    \n    for i in range(2, n + 1):\n        # Single digit decode (if current digit is not '0')\n        if s[i-1] != '0':\n            dp[i] += dp[i-1]\n        \n        # Two digit decode (if the two-digit number is between 10 and 26)\n        two_digit = int(s[i-2:i])\n        if 10 <= two_digit <= 26:\n            dp[i] += dp[i-2]\n    \n    return dp[n]",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b49abe134c43",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T07:28:38.891287"
      },
      {
        "id": "8e7d4f50643e",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "bd308721d0323592",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom enum import Enum\n\nclass Effect(Enum):\n    ALLOW = \"allow\"\n    DENY = \"deny\"\n    AUDIT = \"audit\"\n\nclass Priority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        self.pattern = re.compile(pattern.replace('*', '.*').replace('?', '.'))\n        self.action_pattern = re.compile(action.replace('*', '.*').replace('?', '.')) if action != '*' else None\n        self.effect = Effect(effect) if isinstance(effect, str) else effect\n        self.priority = priority if isinstance(priority, Priority) else Priority(priority)\n        self.conditions = conditions or {}\n        self.metadata = metadata or {}\n        self.hit_count = 0\n    \n    def matches(self, agent, action, context=None):\n        context = context or {}\n        \n        # Check agent pattern\n        if not self.pattern.match(agent):\n            return False\n        \n        # Check action pattern\n        if self.action_pattern and not self.action_pattern.match(action):\n            return False\n        \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n        \n        self.hit_count += 1\n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n        self.rule_index = defaultdict(list)  # Performance optimization\n        self.audit_log = []\n        self.cache = {}\n        self.cache_size = 1000\n    \n    def add_rule(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions, metadata)\n        self.rules.append(rule)\n        # Sort by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority.value, reverse=True)\n        self.clear_cache()\n        return rule\n    \n    def remove_rule(self, rule):\n        if rule in self.rules:\n            self.rules.remove(rule)\n            self.clear_cache()\n    \n    def check(self, agent, action, context=None):\n        cache_key = (agent, action, json.dumps(context or {}, sort_keys=True))\n        \n        if cache_key in self.cache:\n            return self.cache[cache_key]\n        \n        result = self._evaluate_rules(agent, action, context)\n        \n        # Cache management\n        if len(self.cache) >= self.cache_size:\n            # Remove oldest entries (simple FIFO)\n            oldest_keys = list(self.cache.keys())[:self.cache_size // 2]\n            for key in oldest_keys:\n                del self.cache[key]\n        \n        self.cache[cache_key] = result\n        return result\n    \n    def _evaluate_rules(self, agent, action, context):\n        matched_rule = None\n        \n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n              ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "f0480d8f9906",
        "source_paper": "2602.15815v1",
        "created_at": "2026-02-18T07:32:13.170252"
      },
      {
        "id": "23e9a652661b",
        "strategy_name": "Token Budget Enforcer_gen1_gen2",
        "module": "policy",
        "code_hash": "e903498306e3de9e",
        "code_snippet": "import re\nfrom collections import defaultdict\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = defaultdict(list)\n        self.cache = {}\n        self.priority_levels = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}\n    \n    def add_rule(self, pattern, action, priority='medium', conditions=None):\n        \"\"\"Add a policy rule with pattern matching and conditions\"\"\"\n        rule = {\n            'pattern': re.compile(pattern) if isinstance(pattern, str) else pattern,\n            'action': action,\n            'priority': self.priority_levels.get(priority, 2),\n            'conditions': conditions or {}\n        }\n        self.rules[priority].append(rule)\n        self.cache.clear()  # Invalidate cache when rules change\n    \n    def evaluate(self, context):\n        \"\"\"Evaluate context against all rules and return applicable actions\"\"\"\n        cache_key = str(sorted(context.items()))\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n        \n        applicable_actions = []\n        \n        # Process rules by priority order\n        for priority in sorted(self.priority_levels.keys(), key=lambda x: self.priority_levels[x]):\n            for rule in self.rules[priority]:\n                if self._matches_rule(rule, context):\n                    applicable_actions.append({\n                        'action': rule['action'],\n                        'priority': priority,\n                        'matched_pattern': rule['pattern'].pattern if hasattr(rule['pattern'], 'pattern') else str(rule['pattern'])\n                    })\n        \n        self.cache[cache_key] = applicable_actions\n        return applicable_actions\n    \n    def _matches_rule(self, rule, context):\n        \"\"\"Check if a rule matches the given context\"\"\"\n        # Check pattern match\n        target = context.get('target', '')\n        if hasattr(rule['pattern'], 'match'):\n            if not rule['pattern'].match(str(target)):\n                return False\n        \n        # Check additional conditions\n        for condition_key, expected_value in rule['conditions'].items():\n            if context.get(condition_key) != expected_value:\n                return False\n        \n        return True\n    \n    def get_best_action(self, context):\n        \"\"\"Get the highest priority action for given context\"\"\"\n        actions = self.evaluate(context)\n        return actions[0] if actions else None\n\ndef solution(context_data):\n    \"\"\"Main policy evaluation function for agentic OS component\"\"\"\n    engine = PolicyEngine()\n    \n    # Default system policies\n    engine.add_rule(r'^system\\..*', 'allow', 'critical', {'user_type': 'admin'})\n    engine.add_rule(r'^user\\..*', 'review', 'medium')\n    engine.add_rule(r'.*\\.delete$', 'deny', 'high', {'confirmation': False})\n    engine.add_rule(r'.*\\.read$', 'allow', 'low')\n    \n    return engine.evaluate(context_data)",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 2,
        "parent_id": "ec3f2a8ac443",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T07:32:25.892108"
      },
      {
        "id": "025855d5c87a",
        "strategy_name": "Token Budget Enforcer_gen1_gen2",
        "module": "policy",
        "code_hash": "a836463fab233f25",
        "code_snippet": "import time\nimport math\nfrom collections import deque\nimport random\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.0, window_size=20):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.5\n        self.adaptation_factor = 0.15\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Record request pattern with priority scoring\n        priority = self._calculate_priority(tokens)\n        request_data = {\n            'tokens': tokens,\n            'timestamp': time.time(),\n            'granted': False,\n            'priority': priority\n        }\n        \n        # Dynamic limit adjustment based on current load\n        effective_limit = self._get_effective_limit()\n        \n        # Priority-based admission control\n        if self.used + tokens > effective_limit:\n            if priority > 0.7 and self.used + tokens <= self.burst_limit:\n                # Allow high priority requests up to burst limit\n                pass\n            else:\n                self.violations += 1\n                self.violation_streak += 1\n                self.success_streak = 0\n                self._adapt_on_violation()\n                self.request_history.append(request_data)\n                return False\n        \n        self.used += tokens\n        self.peak_usage = max(self.peak_usage, self.used)\n        self.success_streak += 1\n        self.violation_streak = 0\n        request_data['granted'] = True\n        self.request_history.append(request_data)\n        self._adapt_on_success()\n        self._update_efficiency()\n        return True\n    \n    def _calculate_priority(self, tokens):\n        # Higher priority for smaller requests and based on recent patterns\n        size_factor = max(0.1, 1.0 - (tokens / self.limit))\n        \n        # Consider recent success rate\n        recent_requests = list(self.request_history)[-5:]\n        if recent_requests:\n            success_rate = sum(1 for r in recent_requests if r['granted']) / len(recent_requests)\n        else:\n            success_rate = 1.0\n            \n        # Boost priority during low usage periods\n        usage_factor = 1.0 - (self.used / max(1, self.limit))\n        \n        return min(1.0, size_factor * 0.4 + success_rate * 0.3 + usage_factor * 0.3)\n    \n    def _get_effective_limit(self):\n        # Dynamic limit based on recent usage patterns and time of day\n        base = self.limit\n        \n        # Increase limit during low usage periods\n        if self.used < self.limit * 0.3:\n            base = int(base * 1.2)\n        \n        # Consider request velocity\n  ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 2,
        "parent_id": "cf00bbea3162",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T07:39:24.787087"
      },
      {
        "id": "3663a669de84",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "7f82a09b58335d1f",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom typing import Dict, List, Optional, Any\n\nclass PolicyRule:\n    def __init__(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n        self.priority = priority\n        self.conditions = conditions or {}\n        self._compiled_pattern = re.compile(pattern.replace('*', '.*'))\n    \n    def matches(self, agent: str, action: str, context: Dict = None) -> bool:\n        context = context or {}\n        \n        # Check basic pattern and action matching\n        if not self._compiled_pattern.match(agent):\n            return False\n        if self.action != '*' and self.action != action:\n            return False\n            \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context:\n                return False\n            if isinstance(expected, str) and expected.startswith('regex:'):\n                if not re.match(expected[6:], str(context[key])):\n                    return False\n            elif context[key] != expected:\n                return False\n                \n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules: List[PolicyRule] = []\n        self.cache: Dict[str, str] = {}\n        self.stats = defaultdict(int)\n        \n    def add_rule(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions)\n        self.rules.append(rule)\n        self._sort_rules()\n        self.cache.clear()\n        \n    def _sort_rules(self):\n        # Sort by priority (higher first), then by specificity\n        self.rules.sort(key=lambda r: (-r.priority, -len(r.pattern.replace('*', ''))))\n        \n    def check(self, agent: str, action: str, context: Dict = None) -> str:\n        cache_key = f\"{agent}:{action}:{json.dumps(context or {}, sort_keys=True)}\"\n        \n        if cache_key in self.cache:\n            self.stats['cache_hits'] += 1\n            return self.cache[cache_key]\n            \n        self.stats['cache_misses'] += 1\n        \n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n                result = rule.effect\n                self.cache[cache_key] = result\n                self.stats[f'effect_{result}'] += 1\n                return result\n                \n        # Default deny\n        self.cache[cache_key] = 'deny'\n        self.stats['effect_deny'] += 1\n        return 'deny'\n        \n    def batch_check(self, requests: List[tuple]) -> List[str]:\n        return [self.check(*req) for req in requests]\n        \n    def get_matching_rules(self, agent: str, action: str, context: Dict = None) -> List[PolicyRule]:\n        return [rule for rule in self.rules if rule.matches(agent, action, context)]\n        \n    def export_policy(self) -> Dict:\n    ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "f0480d8f9906",
        "source_paper": "2602.15815v1",
        "created_at": "2026-02-18T07:51:17.827292"
      },
      {
        "id": "cf87af4c6dd1",
        "strategy_name": "Token Budget Enforcer_gen1_gen2_gen3",
        "module": "policy",
        "code_hash": "81c53c70ab677f59",
        "code_snippet": "import time\nimport math\nfrom collections import deque\nimport random\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.5, window_size=30):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.3\n        self.adaptation_factor = 0.12\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        self.load_predictor = deque(maxlen=10)\n        self.congestion_threshold = 0.8\n        self.recovery_factor = 0.95\n        \n    def _calculate_priority(self, tokens):\n        current_time = time.time()\n        recent_requests = [r for r in self.request_history if current_time - r['timestamp'] < 1.0]\n        \n        # Higher priority for smaller requests during congestion\n        size_factor = max(0.1, 1.0 - (tokens / self.base_limit))\n        \n        # Boost priority if system is underutilized\n        utilization = self.used / self.limit if self.limit > 0 else 0\n        utilization_boost = 1.2 if utilization < 0.5 else 1.0\n        \n        # Penalty for frequent requests from same pattern\n        frequency_penalty = max(0.5, 1.0 - len(recent_requests) * 0.1)\n        \n        return min(1.0, size_factor * utilization_boost * frequency_penalty)\n    \n    def _get_effective_limit(self):\n        # Predict load trend\n        if len(self.request_history) >= 5:\n            recent_usage = sum(r['tokens'] for r in list(self.request_history)[-5:] if r['granted'])\n            self.load_predictor.append(recent_usage)\n        \n        # Adaptive limit based on recent performance\n        if len(self.load_predictor) >= 3:\n            trend = self.load_predictor[-1] - self.load_predictor[-3]\n            if trend > 0:  # Increasing load\n                adjustment = max(0.7, 1.0 - trend / self.base_limit * 0.3)\n            else:  # Decreasing load\n                adjustment = min(1.3, 1.0 + abs(trend) / self.base_limit * 0.2)\n            \n            return int(self.limit * adjustment)\n        \n        return self.limit\n    \n    def _auto_decay(self):\n        now = time.time()\n        elapsed = now - self.last_decay\n        \n        if elapsed >= self.auto_decay_interval:\n            # Exponential decay with congestion awareness\n            decay_rate = 0.4 if self.used / self.limit > self.congestion_threshold else 0.6\n            decay_amount = int(self.used * decay_rate * (elapsed / self.auto_decay_interval))\n            self.used = max(0, self.used - decay_amount)\n            self.last_decay = now\n    \n    def _adapt_on_violation(self):\n        # More aggressive adaptation during violation streaks\n        streak_multiplier = min(2.0, 1.0 + self.violation_streak * 0.1)\n        reduction = int(self.base",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 3,
        "parent_id": "025855d5c87a",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T08:01:59.693583"
      },
      {
        "id": "8902abd29b76",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "71fbfdb753b82858",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom typing import Dict, List, Optional, Any\n\nclass PolicyRule:\n    def __init__(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n        self.priority = priority\n        self.conditions = conditions or {}\n        self._compiled_pattern = re.compile(pattern.replace('*', '.*'))\n    \n    def matches(self, agent: str, action: str, context: Dict = None) -> bool:\n        context = context or {}\n        \n        # Check agent pattern match\n        if not self._compiled_pattern.match(agent):\n            return False\n            \n        # Check action match\n        if self.action != '*' and self.action != action:\n            return False\n            \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n                \n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules: List[PolicyRule] = []\n        self.cache: Dict[str, str] = {}\n        self.stats = defaultdict(int)\n        \n    def add_rule(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions)\n        self.rules.append(rule)\n        # Sort rules by priority (higher priority first)\n        self.rules.sort(key=lambda r: r.priority, reverse=True)\n        self.cache.clear()  # Clear cache when rules change\n        \n    def check(self, agent: str, action: str, context: Dict = None) -> str:\n        cache_key = f\"{agent}:{action}:{json.dumps(context or {}, sort_keys=True)}\"\n        \n        if cache_key in self.cache:\n            self.stats['cache_hits'] += 1\n            return self.cache[cache_key]\n            \n        self.stats['cache_misses'] += 1\n        \n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n                self.stats[f'effect_{rule.effect}'] += 1\n                self.cache[cache_key] = rule.effect\n                return rule.effect\n                \n        # Default deny\n        self.stats['effect_deny'] += 1\n        self.cache[cache_key] = 'deny'\n        return 'deny'\n    \n    def bulk_check(self, requests: List[tuple]) -> List[str]:\n        \"\"\"Efficiently process multiple policy checks\"\"\"\n        return [self.check(agent, action, context) for agent, action, context in requests]\n    \n    def get_applicable_rules(self, agent: str, action: str, context: Dict = None) -> List[PolicyRule]:\n        \"\"\"Return all rules that would match the given request\"\"\"\n        return [rule for rule in self.rules if rule.matches(agent, action, context)]\n    \n    def export_policy(self) -> Dict:\n        \"\"\"Export policy configuration\"\"\"\n        return {\n            'rules': [\n                {\n                    'patter",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "60b0d387cade",
        "source_paper": "2602.15785v1",
        "created_at": "2026-02-18T08:02:20.620333"
      },
      {
        "id": "1c1d3758483e",
        "strategy_name": "Token Budget Enforcer_gen1_gen2",
        "module": "policy",
        "code_hash": "3d833cd7550ec02a",
        "code_snippet": "import re\nfrom collections import defaultdict\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n        self.cache = {}\n        self.metrics = defaultdict(int)\n    \n    def add_rule(self, condition, action, priority=0):\n        \"\"\"Add a policy rule with condition, action, and priority\"\"\"\n        rule = {\n            'condition': condition,\n            'action': action,\n            'priority': priority,\n            'usage_count': 0\n        }\n        self.rules.append(rule)\n        self.rules.sort(key=lambda x: x['priority'], reverse=True)\n    \n    def evaluate(self, context):\n        \"\"\"Evaluate context against all rules and return applicable actions\"\"\"\n        cache_key = str(sorted(context.items()))\n        if cache_key in self.cache:\n            self.metrics['cache_hits'] += 1\n            return self.cache[cache_key]\n        \n        applicable_actions = []\n        for rule in self.rules:\n            if self._match_condition(rule['condition'], context):\n                applicable_actions.append(rule['action'])\n                rule['usage_count'] += 1\n                self.metrics['rule_matches'] += 1\n        \n        self.cache[cache_key] = applicable_actions\n        self.metrics['evaluations'] += 1\n        return applicable_actions\n    \n    def _match_condition(self, condition, context):\n        \"\"\"Match condition against context using flexible pattern matching\"\"\"\n        if callable(condition):\n            return condition(context)\n        \n        if isinstance(condition, dict):\n            for key, expected in condition.items():\n                if key not in context:\n                    return False\n                \n                actual = context[key]\n                if isinstance(expected, str) and '*' in expected:\n                    pattern = expected.replace('*', '.*')\n                    if not re.match(pattern, str(actual)):\n                        return False\n                elif actual != expected:\n                    return False\n            return True\n        \n        return False\n    \n    def optimize(self):\n        \"\"\"Optimize rule ordering based on usage patterns\"\"\"\n        self.rules.sort(key=lambda x: (x['priority'], x['usage_count']), reverse=True)\n        self.cache.clear()  # Clear cache after reordering\n    \n    def get_metrics(self):\n        \"\"\"Return performance metrics\"\"\"\n        total_evals = self.metrics['evaluations']\n        if total_evals == 0:\n            return {'efficiency': 0.0, 'cache_hit_rate': 0.0}\n        \n        cache_rate = self.metrics['cache_hits'] / total_evals\n        match_rate = self.metrics['rule_matches'] / total_evals\n        \n        return {\n            'efficiency': min(1.0, (cache_rate * 0.4 + match_rate * 0.6)),\n            'cache_hit_rate': cache_rate,\n            'total_evaluations': total_evals\n        }\n\ndef solution(context_data):\n    \"\"\"Main solution function for policy evaluation\"\"\"\n    engine = PolicyEngine()\n    \n    # Add default system policies\n    engine.a",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 2,
        "parent_id": "ec3f2a8ac443",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T08:06:20.232941"
      },
      {
        "id": "a108c1a86e9a",
        "strategy_name": "Token Budget Enforcer_gen1_gen2_gen3",
        "module": "policy",
        "code_hash": "e98c398d52b61829",
        "code_snippet": "import re\nimport json\nimport time\nfrom collections import defaultdict, namedtuple\nfrom functools import lru_cache\n\nPolicyResult = namedtuple('PolicyResult', ['action', 'priority', 'confidence', 'metadata'])\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = defaultdict(list)\n        self.rule_stats = defaultdict(lambda: {'hits': 0, 'last_used': 0})\n        self.priority_levels = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}\n        self.operators = {\n            'eq': lambda a, b: a == b,\n            'ne': lambda a, b: a != b,\n            'gt': lambda a, b: float(a) > float(b),\n            'lt': lambda a, b: float(a) < float(b),\n            'gte': lambda a, b: float(a) >= float(b),\n            'lte': lambda a, b: float(a) <= float(b),\n            'in': lambda a, b: a in b,\n            'contains': lambda a, b: b in str(a),\n            'regex': lambda a, b: bool(re.search(b, str(a)))\n        }\n    \n    def add_rule(self, name, pattern, action, priority='medium', conditions=None, weight=1.0):\n        \"\"\"Add a policy rule with enhanced matching capabilities\"\"\"\n        rule = {\n            'name': name,\n            'pattern': self._compile_pattern(pattern),\n            'action': action,\n            'priority': self.priority_levels.get(priority, 2),\n            'conditions': conditions or [],\n            'weight': weight,\n            'created_at': time.time()\n        }\n        self.rules[priority].append(rule)\n        return rule\n    \n    def _compile_pattern(self, pattern):\n        \"\"\"Compile pattern into matcher function\"\"\"\n        if isinstance(pattern, str):\n            return re.compile(pattern)\n        elif isinstance(pattern, dict):\n            # JSON-like pattern matching\n            return pattern\n        elif callable(pattern):\n            return pattern\n        return re.compile(str(pattern))\n    \n    @lru_cache(maxsize=256)\n    def evaluate(self, context_json):\n        \"\"\"Evaluate context against all rules with confidence scoring\"\"\"\n        context = json.loads(context_json) if isinstance(context_json, str) else context_json\n        results = []\n        \n        # Process rules by priority order\n        for priority in sorted(self.priority_levels.keys(), key=lambda x: self.priority_levels[x]):\n            for rule in self.rules[priority]:\n                match_result = self._evaluate_rule(rule, context)\n                if match_result['matches']:\n                    confidence = self._calculate_confidence(rule, context, match_result)\n                    \n                    result = PolicyResult(\n                        action=rule['action'],\n                        priority=priority,\n                        confidence=confidence,\n                        metadata={\n                            'rule_name': rule['name'],\n                            'match_details': match_result,\n                            'weight': rule['weight']\n                        }\n                    )\n                    results.append(result)\n   ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 3,
        "parent_id": "23e9a652661b",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T08:11:23.023817"
      },
      {
        "id": "5e3019ab1b8c",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "0434eb02f6580dd8",
        "code_snippet": "class PolicyRule:\n    def __init__(self, rule_id, condition, action):\n        self.rule_id = rule_id\n        self.condition = condition\n        self.action = action\n    \n    def __eq__(self, other):\n        if not isinstance(other, PolicyRule):\n            return False\n        return self.rule_id == other.rule_id\n    \n    def __hash__(self):\n        return hash(self.rule_id)\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n    \n    def add_rule(self, rule):\n        if rule not in self.rules:\n            self.rules.append(rule)\n    \n    def remove_rule(self, rule):\n        if rule in self.rules:\n            self.rules.remove(rule)\n    \n    def evaluate(self, context):\n        results = []\n        for rule in self.rules:\n            if rule.condition(context):\n                results.append(rule.action(context))\n        return results",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "3fc1402ad9eb",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T08:16:35.598380"
      },
      {
        "id": "c6caa1146be2",
        "strategy_name": "Token Budget Enforcer_gen1_gen2_gen3_gen4",
        "module": "policy",
        "code_hash": "3df24c1ea75d9702",
        "code_snippet": "import time\nimport math\nfrom collections import deque\nimport random\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.0, window_size=20):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.5\n        self.adaptation_factor = 0.15\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        self.load_predictor = deque(maxlen=8)\n        self.congestion_threshold = 0.75\n        self.recovery_factor = 0.9\n        self.priority_weights = {'size': 0.4, 'urgency': 0.3, 'history': 0.3}\n        \n    def _calculate_priority(self, tokens, urgency=0.5, request_type='normal'):\n        current_time = time.time()\n        recent_requests = [r for r in self.request_history if current_time - r['timestamp'] < 2.0]\n        \n        # Size-based priority (smaller requests get higher priority during congestion)\n        utilization = self.used / self.limit if self.limit > 0 else 0\n        if utilization > self.congestion_threshold:\n            size_priority = max(0.2, 1.0 - (tokens / self.base_limit))\n        else:\n            size_priority = 0.8\n            \n        # Urgency factor\n        urgency_priority = min(1.0, max(0.1, urgency))\n        \n        # Historical performance factor\n        success_rate = self.success_streak / max(1, self.success_streak + self.violation_streak)\n        history_priority = 0.5 + (success_rate * 0.5)\n        \n        # Request type modifier\n        type_modifier = 1.2 if request_type == 'critical' else 1.0\n        \n        weighted_priority = (\n            self.priority_weights['size'] * size_priority +\n            self.priority_weights['urgency'] * urgency_priority +\n            self.priority_weights['history'] * history_priority\n        ) * type_modifier\n        \n        return min(1.0, weighted_priority)\n    \n    def _get_effective_limit(self):\n        current_time = time.time()\n        \n        # Update load predictor\n        if len(self.request_history) >= 3:\n            recent_usage = sum(r['tokens'] for r in list(self.request_history)[-3:] if r['granted'])\n            self.load_predictor.append(recent_usage)\n        \n        # Calculate trend and adapt limit\n        base_limit = self.base_limit\n        if len(self.load_predictor) >= 3:\n            recent_avg = sum(list(self.load_predictor)[-3:]) / 3\n            older_avg = sum(list(self.load_predictor)[:-3]) / max(1, len(self.load_predictor) - 3)\n            \n            trend_factor = recent_avg / max(1, older_avg)\n            \n            if trend_factor > 1.2:  # Increasing load\n                adaptive_limit = int(base_limit * 0.85)\n            elif trend_factor < 0.8:  # Decreasing load\n             ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 4,
        "parent_id": "cf87af4c6dd1",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T08:26:58.245869"
      },
      {
        "id": "944b762a1604",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "c103d0623f53f980",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom enum import Enum\n\nclass Effect(Enum):\n    ALLOW = \"allow\"\n    DENY = \"deny\"\n    AUDIT = \"audit\"\n\nclass Priority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass PolicyRule:\n    def __init__(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        self.pattern = re.compile(pattern.replace('*', '.*').replace('?', '.'))\n        self.action_pattern = re.compile(action.replace('*', '.*').replace('?', '.')) if action != '*' else None\n        self.effect = Effect(effect) if isinstance(effect, str) else effect\n        self.priority = priority if isinstance(priority, Priority) else Priority(priority)\n        self.conditions = conditions or {}\n        self.metadata = metadata or {}\n        self.hit_count = 0\n    \n    def matches(self, agent, action, context=None):\n        context = context or {}\n        \n        # Check agent pattern\n        if not self.pattern.match(agent):\n            return False\n            \n        # Check action pattern\n        if self.action_pattern and not self.action_pattern.match(action):\n            return False\n            \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n                \n        self.hit_count += 1\n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n        self.rule_cache = {}\n        self.audit_log = []\n        self.stats = defaultdict(int)\n    \n    def add_rule(self, pattern, action, effect, priority=Priority.MEDIUM, conditions=None, metadata=None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions, metadata)\n        self.rules.append(rule)\n        self._sort_rules()\n        self._clear_cache()\n        return rule\n    \n    def _sort_rules(self):\n        \"\"\"Sort rules by priority (highest first) then by specificity\"\"\"\n        def rule_key(rule):\n            specificity = len(rule.pattern.pattern) + len(rule.conditions)\n            return (-rule.priority.value, -specificity)\n        self.rules.sort(key=rule_key)\n    \n    def _clear_cache(self):\n        self.rule_cache.clear()\n    \n    def check(self, agent, action, context=None):\n        cache_key = (agent, action, json.dumps(context or {}, sort_keys=True))\n        \n        if cache_key in self.rule_cache:\n            self.stats['cache_hits'] += 1\n            return self.rule_cache[cache_key]\n        \n        self.stats['evaluations'] += 1\n        context = context or {}\n        \n        for rule in self.rules:\n            if rule.matches(agent, action, context):\n                result = {\n                    'effect': rule.effect.value,\n                    'rule': rule,\n                    'priority': rule.priority.value,\n                    'metadata': rule.metadata\n                }\n                \n                if rule.effect == Effect.AU",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "3fc1402ad9eb",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T08:30:41.746400"
      },
      {
        "id": "5d3e2983e129",
        "strategy_name": "Policy Rule Engine_gen1",
        "module": "policy",
        "code_hash": "d1fc2e6e502282d5",
        "code_snippet": "import re\nimport json\nfrom collections import defaultdict\nfrom typing import Dict, List, Optional, Set\n\nclass PolicyRule:\n    def __init__(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        self.pattern = pattern\n        self.action = action\n        self.effect = effect\n        self.priority = priority\n        self.conditions = conditions or {}\n        self._compiled_pattern = re.compile(pattern.replace('*', '.*'))\n    \n    def matches(self, agent: str, action: str, context: Dict = None) -> bool:\n        context = context or {}\n        \n        # Check agent pattern\n        if not self._compiled_pattern.match(agent):\n            return False\n            \n        # Check action\n        if self.action != '*' and self.action != action:\n            return False\n            \n        # Check additional conditions\n        for key, expected in self.conditions.items():\n            if key not in context or context[key] != expected:\n                return False\n                \n        return True\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules: List[PolicyRule] = []\n        self.cache: Dict[str, str] = {}\n        self.audit_log: List[Dict] = []\n        self.rule_stats = defaultdict(int)\n        \n    def add_rule(self, pattern: str, action: str, effect: str, priority: int = 0, conditions: Dict = None):\n        rule = PolicyRule(pattern, action, effect, priority, conditions)\n        self.rules.append(rule)\n        self._sort_rules()\n        self.cache.clear()\n        \n    def _sort_rules(self):\n        \"\"\"Sort rules by priority (higher first), then by specificity\"\"\"\n        self.rules.sort(key=lambda r: (-r.priority, -len(r.pattern.replace('*', ''))))\n        \n    def check(self, agent: str, action: str, context: Dict = None) -> str:\n        cache_key = f\"{agent}:{action}:{json.dumps(context or {}, sort_keys=True)}\"\n        \n        if cache_key in self.cache:\n            return self.cache[cache_key]\n            \n        result = self._evaluate(agent, action, context)\n        self.cache[cache_key] = result\n        \n        # Audit logging\n        self.audit_log.append({\n            'agent': agent,\n            'action': action,\n            'context': context,\n            'result': result\n        })\n        \n        return result\n        \n    def _evaluate(self, agent: str, action: str, context: Dict = None) -> str:\n        for i, rule in enumerate(self.rules):\n            if rule.matches(agent, action, context):\n                self.rule_stats[i] += 1\n                return rule.effect\n        return 'deny'\n        \n    def bulk_check(self, requests: List[tuple]) -> List[str]:\n        \"\"\"Efficiently check multiple requests\"\"\"\n        return [self.check(*req) for req in requests]\n        \n    def get_applicable_rules(self, agent: str, action: str, context: Dict = None) -> List[PolicyRule]:\n        \"\"\"Return all rules that would match the given request\"\"\"\n        return [rule for rule in self.rules",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "f0480d8f9906",
        "source_paper": "2602.15815v1",
        "created_at": "2026-02-18T08:31:02.051819"
      },
      {
        "id": "701077289610",
        "strategy_name": "Token Budget Enforcer_gen1_gen2",
        "module": "policy",
        "code_hash": "0168725ee3373c4b",
        "code_snippet": "import time\nimport math\nfrom collections import deque\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=2.0, window_size=20):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 0.5\n        self.adaptation_factor = 0.15\n        self.success_streak = 0\n        self.violation_streak = 0\n        self.peak_usage = 0\n        self.efficiency_score = 1.0\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Record request pattern with context\n        current_time = time.time()\n        self.request_history.append({\n            'tokens': tokens,\n            'timestamp': current_time,\n            'granted': False,\n            'usage_before': self.used,\n            'limit_at_time': self.limit\n        })\n        \n        # Dynamic limit adjustment based on recent patterns\n        effective_limit = self._calculate_effective_limit()\n        \n        # Check against dynamic limit\n        if self.used + tokens > effective_limit:\n            self.violations += 1\n            self.violation_streak += 1\n            self.success_streak = 0\n            self._adapt_on_violation()\n            return False\n            \n        self.used += tokens\n        self.peak_usage = max(self.peak_usage, self.used)\n        self.success_streak += 1\n        self.violation_streak = 0\n        self.request_history[-1]['granted'] = True\n        self._adapt_on_success()\n        self._update_efficiency()\n        return True\n    \n    def _calculate_effective_limit(self):\n        # Use burst limit during low usage periods, tighten during high usage\n        usage_ratio = self.used / max(1, self.limit)\n        \n        if usage_ratio < 0.3:  # Low usage - allow burst\n            return self.burst_limit\n        elif usage_ratio < 0.7:  # Medium usage - gradual transition\n            blend_factor = (usage_ratio - 0.3) / 0.4\n            return int(self.burst_limit * (1 - blend_factor) + self.limit * blend_factor)\n        else:  # High usage - strict limit\n            return self.limit\n    \n    def _auto_decay(self):\n        now = time.time()\n        if now - self.last_decay >= self.auto_decay_interval:\n            elapsed_intervals = (now - self.last_decay) / self.auto_decay_interval\n            # Adaptive decay rate based on usage patterns\n            base_decay = 0.7\n            usage_factor = min(1.0, self.used / max(1, self.limit))\n            decay_rate = base_decay + (0.2 * usage_factor)  # Faster decay when heavily used\n            decay_factor = decay_rate ** elapsed_intervals\n            self.decay(decay_factor)\n            self.last_decay = now\n    \n    def decay(self, factor=0.7):\n        old_used = self.used\n        self.used = max(0, int(self.used * factor))\n",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 2,
        "parent_id": "cf00bbea3162",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T08:36:15.216670"
      },
      {
        "id": "297a000e54c8",
        "strategy_name": "Policy Rule Engine_gen1_gen2",
        "module": "policy",
        "code_hash": "8f7da6f79d7fc342",
        "code_snippet": "import json\nimport re\nfrom collections import defaultdict, namedtuple\nfrom typing import Any, Dict, List, Callable, Optional, Union\n\nPolicyResult = namedtuple('PolicyResult', ['rule_id', 'action', 'result', 'priority', 'metadata'])\n\nclass PolicyRule:\n    def __init__(self, rule_id: str, condition: Callable, action: Callable, \n                 priority: int = 0, metadata: Optional[Dict] = None):\n        self.rule_id = rule_id\n        self.condition = condition\n        self.action = action\n        self.priority = priority\n        self.metadata = metadata or {}\n        self.execution_count = 0\n        self.success_count = 0\n        \n    def __eq__(self, other):\n        if not isinstance(other, PolicyRule):\n            return False\n        return self.rule_id == other.rule_id\n    \n    def __hash__(self):\n        return hash(self.rule_id)\n    \n    def __lt__(self, other):\n        return self.priority < other.priority\n    \n    def evaluate_condition(self, context: Dict[str, Any]) -> bool:\n        try:\n            return bool(self.condition(context))\n        except Exception:\n            return False\n    \n    def execute_action(self, context: Dict[str, Any]) -> Any:\n        self.execution_count += 1\n        try:\n            result = self.action(context)\n            self.success_count += 1\n            return result\n        except Exception as e:\n            return {\"error\": str(e), \"rule_id\": self.rule_id}\n\nclass PolicyEngine:\n    def __init__(self):\n        self.rules = []\n        self.rule_groups = defaultdict(list)\n        self.execution_history = []\n        self.max_history = 1000\n        \n    def add_rule(self, rule: PolicyRule, group: Optional[str] = None):\n        if rule not in self.rules:\n            self.rules.append(rule)\n            self.rules.sort(key=lambda r: r.priority, reverse=True)\n            if group:\n                self.rule_groups[group].append(rule)\n    \n    def remove_rule(self, rule: Union[PolicyRule, str]):\n        if isinstance(rule, str):\n            rule = self.get_rule_by_id(rule)\n        if rule and rule in self.rules:\n            self.rules.remove(rule)\n            for group_rules in self.rule_groups.values():\n                if rule in group_rules:\n                    group_rules.remove(rule)\n    \n    def get_rule_by_id(self, rule_id: str) -> Optional[PolicyRule]:\n        for rule in self.rules:\n            if rule.rule_id == rule_id:\n                return rule\n        return None\n    \n    def evaluate(self, context: Dict[str, Any], group: Optional[str] = None, \n                limit: Optional[int] = None) -> List[PolicyResult]:\n        rules_to_evaluate = self.rule_groups.get(group, self.rules) if group else self.rules\n        results = []\n        \n        for rule in rules_to_evaluate:\n            if limit and len(results) >= limit:\n                break\n                \n            if rule.evaluate_condition(context):\n                action_result = rule.execute_action(context)\n                policy_result = PolicyR",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 2,
        "parent_id": "5e3019ab1b8c",
        "source_paper": "2602.15813v1",
        "created_at": "2026-02-18T08:39:56.019292"
      },
      {
        "id": "621eed5a25b6",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "90b20bc2cda85dbe",
        "code_snippet": "import time\nimport math\nfrom collections import deque\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=1.5, window_size=10):\n        self.base_limit = limit\n        self.current_limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.burst_factor = burst_factor\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 1.0\n        self.adaptation_factor = 0.1\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Track request pattern\n        self.request_history.append(tokens)\n        \n        # Check against burst limit first\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            self._adapt_on_violation()\n            return False\n            \n        self.used += tokens\n        self._adapt_on_success()\n        return True\n    \n    def _auto_decay(self):\n        now = time.time()\n        if now - self.last_decay >= self.auto_decay_interval:\n            elapsed = now - self.last_decay\n            decay_factor = math.exp(-elapsed / 2.0)  # Exponential decay\n            self.decay(decay_factor)\n            self.last_decay = now\n    \n    def _adapt_on_violation(self):\n        # Reduce limit temporarily when violations occur\n        if self.violations > 0 and self.violations % 3 == 0:\n            reduction = 1 - (self.adaptation_factor * min(self.violations / 10, 0.5))\n            self.current_limit = max(int(self.base_limit * reduction), self.base_limit // 2)\n            self.burst_limit = int(self.current_limit * self.burst_factor)\n    \n    def _adapt_on_success(self):\n        # Gradually restore limit on successful requests\n        if self.current_limit < self.base_limit:\n            self.current_limit = min(self.current_limit + int(self.base_limit * 0.05), self.base_limit)\n            self.burst_limit = int(self.current_limit * self.burst_factor)\n    \n    def decay(self, factor=0.8):\n        self.used = int(self.used * factor)\n    \n    def get_policy_decision(self, requested_tokens):\n        \"\"\"Core policy decision with recommendation\"\"\"\n        if self.used + requested_tokens <= self.current_limit:\n            return {\"allow\": True, \"priority\": \"normal\", \"reason\": \"within_limit\"}\n        elif self.used + requested_tokens <= self.burst_limit:\n            return {\"allow\": True, \"priority\": \"burst\", \"reason\": \"burst_capacity\"}\n        else:\n            # Calculate suggested tokens that would be allowed\n            available = max(0, self.burst_limit - self.used)\n            return {\n                \"allow\": False, \n                \"priority\": \"denied\", \n                \"reason\": \"exceeds_burst\",\n                \"suggested_tokens\": available,\n                \"retry_after\": self._estimate_retry_time()\n            }\n    \n    def _estimate_retry_time(self):\n        if not self.re",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b4e80c865dfe",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T08:40:16.599971"
      },
      {
        "id": "255567041c0c",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "0cd3b9d1cbc6d6d9",
        "code_snippet": "import time\nfrom collections import deque\nfrom math import exp\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=1.5, window_size=10):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.used = 0\n        self.violations = 0\n        self.last_reset = time.time()\n        self.reset_interval = 60  # seconds\n        \n        # Adaptive components\n        self.request_history = deque(maxlen=window_size)\n        self.violation_history = deque(maxlen=window_size)\n        self.adaptation_factor = 1.0\n        \n    def request(self, tokens, priority=1.0):\n        self._auto_reset()\n        \n        # Priority-based adjustment\n        effective_tokens = max(1, int(tokens / priority))\n        \n        # Check against current limits\n        if self.used + effective_tokens > self.burst_limit:\n            self.violations += 1\n            self.violation_history.append(1)\n            self.request_history.append(tokens)\n            self._adapt_limits()\n            return False\n            \n        self.used += effective_tokens\n        self.violation_history.append(0)\n        self.request_history.append(tokens)\n        self._adapt_limits()\n        return True\n    \n    def _auto_reset(self):\n        \"\"\"Automatic periodic reset with exponential decay\"\"\"\n        now = time.time()\n        if now - self.last_reset > self.reset_interval:\n            self.decay(0.7)\n            self.last_reset = now\n    \n    def _adapt_limits(self):\n        \"\"\"Dynamically adjust limits based on usage patterns\"\"\"\n        if len(self.violation_history) < 5:\n            return\n            \n        recent_violations = sum(list(self.violation_history)[-5:])\n        avg_request_size = sum(self.request_history) / len(self.request_history)\n        \n        # Increase limits if low violations and high utilization\n        if recent_violations == 0 and self.utilization > 0.8:\n            self.adaptation_factor = min(1.3, self.adaptation_factor * 1.05)\n        # Decrease limits if high violations\n        elif recent_violations >= 3:\n            self.adaptation_factor = max(0.7, self.adaptation_factor * 0.95)\n            \n        self.limit = int(self.base_limit * self.adaptation_factor)\n        self.burst_limit = int(self.limit * 1.5)\n    \n    def decay(self, factor=0.8):\n        \"\"\"Exponential decay with minimum threshold\"\"\"\n        self.used = max(0, int(self.used * factor))\n    \n    def reserve(self, tokens, duration=30):\n        \"\"\"Reserve tokens for future use\"\"\"\n        if self.used + tokens <= self.burst_limit:\n            self.used += tokens\n            return True\n        return False\n    \n    @property\n    def utilization(self):\n        return round(self.used / self.limit, 3) if self.limit else 0\n    \n    @property\n    def health_score(self):\n        \"\"\"Overall health metric (0-1, higher is better)\"\"\"\n        violation_rate = self.violations / max(1, len(self.request_history))\n        util_score = ",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b49abe134c43",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T08:45:29.474763"
      },
      {
        "id": "55394a3ee288",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "d82f6b6cdc2f1df9",
        "code_snippet": "import time\nimport math\nfrom collections import deque\n\nclass AdaptiveTokenBudget:\n    def __init__(self, limit, burst_factor=1.5, window_size=10):\n        self.base_limit = limit\n        self.limit = limit\n        self.burst_limit = int(limit * burst_factor)\n        self.burst_factor = burst_factor\n        self.used = 0\n        self.violations = 0\n        self.window_size = window_size\n        self.request_history = deque(maxlen=window_size)\n        self.last_decay = time.time()\n        self.auto_decay_interval = 1.0\n        self.adaptation_factor = 0.1\n        \n    def request(self, tokens):\n        self._auto_decay()\n        \n        # Record request pattern\n        self.request_history.append(tokens)\n        \n        # Check against burst limit\n        if self.used + tokens > self.burst_limit:\n            self.violations += 1\n            self._adapt_on_violation()\n            return False\n            \n        self.used += tokens\n        self._adapt_on_success()\n        return True\n    \n    def _auto_decay(self):\n        current_time = time.time()\n        if current_time - self.last_decay > self.auto_decay_interval:\n            decay_factor = min(0.9, 0.7 + (current_time - self.last_decay) * 0.1)\n            self.decay(decay_factor)\n            self.last_decay = current_time\n    \n    def _adapt_on_violation(self):\n        # Temporarily reduce limit on violations\n        if len(self.request_history) >= 3:\n            avg_request = sum(self.request_history) / len(self.request_history)\n            if avg_request > self.limit * 0.3:  # High pressure\n                self.limit = max(self.base_limit * 0.8, self.limit * 0.95)\n    \n    def _adapt_on_success(self):\n        # Gradually restore limit on successful requests\n        if self.violations == 0 and len(self.request_history) >= 5:\n            self.limit = min(self.base_limit, self.limit * 1.01)\n        \n        # Update burst limit\n        self.burst_limit = int(self.limit * self.burst_factor)\n    \n    def decay(self, factor=0.8):\n        self.used = int(self.used * factor)\n        if self.used < self.limit * 0.2:  # Low usage, reset violations\n            self.violations = max(0, self.violations - 1)\n    \n    def get_pressure_score(self):\n        if not self.request_history:\n            return 0.0\n        recent_demand = sum(self.request_history)\n        capacity = self.limit * len(self.request_history)\n        return min(1.0, recent_demand / capacity) if capacity > 0 else 0.0\n    \n    def get_health_metrics(self):\n        return {\n            'utilization': self.utilization,\n            'pressure': self.get_pressure_score(),\n            'violations': self.violations,\n            'efficiency': max(0, 1.0 - (self.violations * 0.1)),\n            'adaptive_limit': self.limit,\n            'burst_available': max(0, self.burst_limit - self.used)\n        }\n    \n    @property\n    def utilization(self):\n        return round(self.used / self.limit, 3) if self.limit else 0\n\n# Test the adaptive budget\nb = A",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b49abe134c43",
        "source_paper": "2602.15004v1",
        "created_at": "2026-02-18T08:50:37.988641"
      },
      {
        "id": "09e29304f06c",
        "strategy_name": "Token Budget Enforcer_gen1",
        "module": "policy",
        "code_hash": "e1216d48047360a6",
        "code_snippet": "def solution(s: str) -> str:\n    # Find all positions of 'a' in the string\n    a_positions = []\n    for i, char in enumerate(s):\n        if char == 'a':\n            a_positions.append(i)\n    \n    # If there are no 'a's, return the string with the last character changed to 'a'\n    if not a_positions:\n        return s[:-1] + 'a'\n    \n    # Convert string to list for easier manipulation\n    chars = list(s)\n    \n    # Try to find a character that can be decremented\n    for pos in a_positions:\n        # Look to the right of each 'a'\n        for i in range(pos + 1, len(chars)):\n            if chars[i] > 'a':\n                chars[i] = chr(ord(chars[i]) - 1)\n                return ''.join(chars)\n    \n    # If no character to the right of any 'a' can be decremented,\n    # decrement the last character (which must be > 'a' since we have 'a's)\n    if chars[-1] > 'a':\n        chars[-1] = chr(ord(chars[-1]) - 1)\n        return ''.join(chars)\n    \n    # If last character is 'a', find the rightmost non-'a' character\n    for i in range(len(chars) - 2, -1, -1):\n        if chars[i] > 'a':\n            chars[i] = chr(ord(chars[i]) - 1)\n            return ''.join(chars)\n    \n    # This should never happen given the constraints\n    return s",
        "fitness_scores": [],
        "current_fitness": 0.5,
        "generation": 1,
        "parent_id": "b4e80c865dfe",
        "source_paper": "2602.15830v1",
        "created_at": "2026-02-18T09:01:46.149300"
      }
    ]
  }
}